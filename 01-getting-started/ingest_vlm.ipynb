{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Image description\" width=\"160\" />\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Ingesting Documents with Visual Documents \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this tutorial, we'll walk through how to ingest documents with visual content into Contextual's datastore using the API. The ingestion process will extract text, tables, and visual elements from documents like PDFs, making them searchable and queryable. We'll use the ContextualAI client to handle the ingestion, similar to the standard document ingestion process.\n",
    "\n",
    "### Important Links\n",
    "- [Ingesting documents API References](https://docs.contextual.ai/api-reference/datastores-documents/ingest-document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "\n",
    "API_HOST=\"https://api.app.contextual.ai\"\n",
    "TOKEN= \"YOUR_API_KEY\"\n",
    "DATASTORE_NAME=\"DATASTORE_NAME\"\n",
    "DATASTORE_ID=\"DATASTORE_ID\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Advanced Document Extraction with Visual Language Models \n",
    "\n",
    " Contextual AI supports advanced document extraction using Visual Language Models (VLMs). This enables more sophisticated analysis of visual elements, tables, and layouts in documents, going beyond traditional text-only extraction.\n",
    "\n",
    " define the VLM_PROMPT here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VLM_PROMPT = \"\"\"\n",
    "# Add your custom VLM prompt here to control how visual elements are analyzed and described\n",
    "# Example format:\n",
    "# - Describe the type of visual (image, chart, table, code, etc.)\n",
    "# - List key visible elements\n",
    "# - Note any relevant text or data\n",
    "# - Explain the visual's purpose\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure datastore to enable:\n",
    "1. V2 extraction pipeline - Required for visual content extraction\n",
    "2. Static captioning with custom prompt - For consistent image descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datastore_config = {\n",
    "      \"datastore_type\": \"UNSTRUCTURED\",\n",
    "      \"name\": DATASTORE_NAME,\n",
    "      \"configuration\": {\n",
    "          \"enable_v2_extraction_pipeline\": True,  # Enable V2 pipeline for visual content\n",
    "          \"extraction\": {\n",
    "              \"static_captioning_prompt\": VLM_PROMPT  # Custom prompt for image captioning\n",
    "                  }\n",
    "          }\n",
    "}\n",
    "response = requests.put(f\"{API_HOST}/v1/datastores/{DATASTORE_ID}\", headers=headers, data=json.dumps(datastore_config))\n",
    "assert response.status_code == 200, response.text\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx-shared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
