{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPJnDH0HhXB"
      },
      "source": [
        "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Image description\" width=\"160\" />\n",
        "\n",
        "<br/>\n",
        "\n",
        "# Using the Contextual AI Reranker\n",
        "\n",
        "\n",
        "Contextual AI's reranker is the first with instruction-following capabilities to handle conflicts in retrieval. It is the most accurate reranker in the world per industry-leading benchmarks like BEIR. To learn more about the reranker and its importance in RAG pipelines, please see our [blog](https://contextual.ai/blog/introducing-instruction-following-reranker/).\n",
        "\n",
        "This notebook demonstrates how to use the reranker with the Contextual API directly, our Python SDK, and our Langchain package. We'll use the same example throughout.\n",
        "\n",
        "<br/>\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/03-standalone-api/03-rerank/rerank.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29JM_ro71PR2"
      },
      "source": [
        "## Global Variables and Examples\n",
        "\n",
        "First, we will set up the global variables and examples we'll use with each different implementation method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get(\"API_TOKEN\")\n",
        "base_url = \"https://api.contextual.ai/v1\"\n",
        "rerank_api_endpoint = f\"{base_url}/rerank\""
      ],
      "metadata": {
        "id": "o-o5xUaOhwDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\"\n",
        "\n",
        "instruction = \"Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\"\n",
        "\n",
        "documents = [\n",
        "    \"Following detailed cost analysis and market research, we have implemented the following changes: AI training clusters will see a 15% uplift in raw compute performance, enterprise support packages are being restructured, and bulk procurement programs (100+ units) for the RTX 5090 Enterprise series will operate on a $2,899 baseline.\",\n",
        "    \"Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 per unit. This pricing for RTX 5090 enterprise bulk orders has been confirmed across all major distribution channels.\",\n",
        "    \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead.\"\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    \"Date: January 15, 2025. Source: NVIDIA Enterprise Sales Portal. Classification: Internal Use Only\",\n",
        "    \"TechAnalytics Research Group. 11/30/2023.\",\n",
        "    \"January 25, 2025; NVIDIA Enterprise Sales Portal; Internal Use Only\"\n",
        "]\n",
        "\n",
        "model = \"ctxl-rerank-en-v1-instruct\""
      ],
      "metadata": {
        "id": "9tT8YC0SAzOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcqh_-j1MzCn"
      },
      "source": [
        "## REST API implementation\n",
        "\n",
        "You can use our API directly with the `requests` package. See [docs.contextual.ai](https://docs.contextual.ai/reference/rerank_rerank_post) for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"authorization\": f\"Bearer {api_key}\"\n",
        "}"
      ],
      "metadata": {
        "id": "mnElOk9mhDLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payload = {\n",
        "    \"query\": query,\n",
        "    \"instruction\": instruction,\n",
        "    \"documents\": documents,\n",
        "    \"metadata\": metadata,\n",
        "    \"model\": model\n",
        "}\n",
        "\n",
        "rerank_response = requests.post(rerank_api_endpoint, json=payload, headers=headers)\n",
        "\n",
        "print(rerank_response.json())"
      ],
      "metadata": {
        "id": "JCpvoaYeiXQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBNaPz90tgAQ"
      },
      "source": [
        "## Python SDK\n",
        "\n",
        "We also have a [Python SDK](https://github.com/ContextualAI/contextual-client-python/blob/main/api.md#rerank)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from contextual import ContextualAI\n",
        "except:\n",
        "  %pip install contextual-client\n",
        "  from contextual import ContextualAI\n",
        "\n",
        "client = ContextualAI (api_key = api_key, base_url = base_url)"
      ],
      "metadata": {
        "id": "YCAEcszVhT0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rerank_response = client.rerank.create(\n",
        "    query = query,\n",
        "    instruction = instruction,\n",
        "    documents = documents,\n",
        "    metadata = metadata,\n",
        "    model = model\n",
        ")\n",
        "\n",
        "print(rerank_response.to_dict())"
      ],
      "metadata": {
        "id": "ert_nYl-kHNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpS99F8itgAQ"
      },
      "source": [
        "## Langchain\n",
        "\n",
        "We also have a Langchain package. See details [here](https://pypi.org/project/langchain-contextual/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from langchain_contextual import ContextualRerank\n",
        "except:\n",
        "  %pip install langchain-contextual\n",
        "  from langchain_contextual import ContextualRerank\n",
        "\n",
        "from langchain_core.documents import Document"
      ],
      "metadata": {
        "id": "6Ykml3Iamco5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intialize Contextual reranker via langchain_contextual\n",
        "compressor = ContextualRerank(\n",
        "    model=model,\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "# Prepare metadata in dictionary format for Langchain Document class\n",
        "metadata_dict = [\n",
        "    {\n",
        "        \"Date\": \"January 15, 2025\",\n",
        "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "        \"Classification\": \"Internal Use Only\"\n",
        "    },\n",
        "    {\n",
        "        \"Date\": \"11/30/2023\",\n",
        "        \"Source\": \"TechAnalytics Research Group\"\n",
        "    },\n",
        "    {\n",
        "        \"Date\": \"January 25, 2025\",\n",
        "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "        \"Classification\": \"Internal Use Only\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# prepare documents as langchain Document objects\n",
        "# metadata stored in document objects will be extracted and used for reranking\n",
        "langchain_documents = [\n",
        "    Document(page_content=content, metadata=metadata_dict[i])\n",
        "    for i, content in enumerate(documents)\n",
        "]\n",
        "\n",
        "# print to validate langchain document\n",
        "print(langchain_documents[0])"
      ],
      "metadata": {
        "id": "8OtjuUo9kLDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use compressor.compress_documents to rerank the documents\n",
        "reranked_documents = compressor.compress_documents(\n",
        "    query=query,\n",
        "    instruction=instruction,\n",
        "    documents=langchain_documents,\n",
        ")\n",
        "\n",
        "print(reranked_documents)"
      ],
      "metadata": {
        "id": "g0FTfPiY-FY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
