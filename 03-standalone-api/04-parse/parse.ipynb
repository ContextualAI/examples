{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02-H04579t8u"
   },
   "source": [
    "# Using the Contextual AI Document Parser\n",
    "\n",
    "This notebook demonstrates how to use `/parse` with the [Contextual API](https://docs.contextual.ai/api-reference/parse/parse-file) directly and our [Python SDK](https://github.com/ContextualAI/contextual-client-python/tree/main). We'll use the same doc, [Attention is All You Need](https://arxiv.org/pdf/1706.03762) for both. Please see our [blog post](https://contextual.ai/blog/...) for more details on its comparative advantages to other parsers.\n",
    "\n",
    "This notebook has 6 major sections:\n",
    "\n",
    "0. Fetch doc and API key\n",
    "1. REST API implementation\n",
    "2. Contextual SDK\n",
    "3. Parse UI\n",
    "4. Output Types\n",
    "5. Section Metadata\n",
    "6. Table Extraction\n",
    "\n",
    "You can run this notebook entirely in Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/03-standalone-api/03-parse/parse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWm3zGBbAAC7"
   },
   "source": [
    "## 0. Fetch the doc & Set API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8aXLCh-UeWR"
   },
   "source": [
    "First, we will fetch the document that we'll use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-Xs20pz9Heg"
   },
   "outputs": [],
   "source": [
    "url = \"https://arxiv.org/pdf/1706.03762\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_riFCPQ9JyI"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download doc\n",
    "file_path = \"attention-is-all-you-need.pdf\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jewW6qJwAKsS"
   },
   "source": [
    "### API Key ðŸ”‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2Jrcac9AKR2"
   },
   "outputs": [],
   "source": [
    "# Set the API key in the ðŸ”‘ pane of google colab\n",
    "from google.colab import userdata\n",
    "api_key = userdata.get('CONTEXTUAL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOxjaakzANCV"
   },
   "source": [
    "# 1. REST API implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hg81EQ9hZsY7"
   },
   "source": [
    "You can use our API directly with the `requests` package. See [docs.contextual.ai](https://docs.contextual.ai/api-reference/parse/parse-file) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwMbaFcv9sRT"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "base_url = \"https://api.contextual.ai/v1\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov3jw3Ir-d0F"
   },
   "source": [
    "## 1.1 Submit Parse Job\n",
    "\n",
    "Next, we'll define the configuration for our parse job and submit it. This initiates an async parse job and returns a `job_id` we can use to monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ilX_lgcR-LKe",
    "outputId": "5e2bd4ef-3f8e-4e8e-80c7-0470a6d6e53a"
   },
   "outputs": [],
   "source": [
    "url = f\"{base_url}/parse\"\n",
    "\n",
    "config = {\n",
    "    \"parse_mode\": \"standard\",\n",
    "    \"figure_caption_mode\": \"concise\",\n",
    "    \"enable_document_hierarchy\": True,\n",
    "    \"page_range\": \"0-5\",\n",
    "}\n",
    "\n",
    "with open(file_path, \"rb\") as fp:\n",
    "    file = {\"raw_file\": fp}\n",
    "    result = requests.post(url, headers=headers, data=config, files=file)\n",
    "    response = json.loads(result.text)\n",
    "\n",
    "job_id = response['job_id']\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fg-uBKuC-wXD",
    "outputId": "7a22aa90-4685-4e8c-d4a9-e5cae3e318fe"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVrZE0MK-muR"
   },
   "source": [
    "## 1.2 Monitor Job Status\n",
    "\n",
    "Using the `job_id` from above, we can monitor the status of our parse job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmHJiE6G-Ly3",
    "outputId": "81911fb1-58c7-48e9-ef18-0dba72f26ad1"
   },
   "outputs": [],
   "source": [
    "# Check on parse job status\n",
    "from time import sleep\n",
    "\n",
    "url = f\"{base_url}/parse/jobs/{job_id}/status\"\n",
    "\n",
    "while True:\n",
    "    result = requests.get(url, headers=headers)\n",
    "    parse_response = json.loads(result.text)['status']\n",
    "    print(f\"Job is {parse_response}\")\n",
    "    if parse_response == \"completed\":\n",
    "        break\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dWLNt3KGS6d"
   },
   "source": [
    "## 1.3 List all jobs\n",
    "\n",
    "If we submit multiple jobs and want to see the status of each of them, then we can use the list jobs api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jF65e7HGRBu",
    "outputId": "1bdb92a5-84e8-4f5d-8800-46baed93c4d4"
   },
   "outputs": [],
   "source": [
    "url = f\"{base_url}/parse/jobs\"\n",
    "\n",
    "result = requests.get(url, headers=headers)\n",
    "parse_response = json.loads(result.text)\n",
    "parse_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Peszi92i-qXx"
   },
   "source": [
    "## 1.4 Get Parse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBzELtL7-M0K",
    "outputId": "c2f1a56d-9800-45ae-d9e3-f933746cb79a"
   },
   "outputs": [],
   "source": [
    "url = f\"{base_url}/parse/jobs/{job_id}/results\"\n",
    "\n",
    "output_types = [\"markdown-per-page\"]\n",
    "\n",
    "result = requests.get(\n",
    "    url,\n",
    "    headers=headers,\n",
    "    params={\"output_types\": \",\".join(output_types)},\n",
    ")\n",
    "\n",
    "result = json.loads(result.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkT9x62wJodW"
   },
   "source": [
    "## 1.6 Display 1st Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "46ahgvFvJhwP",
    "outputId": "d691ab6f-aca8-4596-f82e-88e0557c9170"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(result['pages'][0]['markdown']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE8agDhjA7jq"
   },
   "source": [
    "# 2. Contextual SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwAcEfQ_A-JM",
    "outputId": "844e220b-70c2-41a7-f274-a56cddcae0d2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from contextual import ContextualAI\n",
    "except:\n",
    "  %pip install --upgrade --quiet contextual-client\n",
    "  from contextual import ContextualAI\n",
    "\n",
    "# Setup Contextual Python SDK\n",
    "client = ContextualAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwygsQe0Ep4s"
   },
   "source": [
    "## 2.1 Submit Parse Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bN-1c2miDN1K",
    "outputId": "289eea63-d968-4a8d-faac-978b39e9b308"
   },
   "outputs": [],
   "source": [
    "with open(file_path, \"rb\") as fp:\n",
    "    response = client.parse.create(\n",
    "        raw_file=fp,\n",
    "        parse_mode=\"standard\",\n",
    "        figure_caption_mode=\"concise\",\n",
    "        enable_document_hierarchy=True,\n",
    "        page_range=\"0-5\",\n",
    "    )\n",
    "\n",
    "job_id = response.job_id\n",
    "job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqGKdWtGEsut"
   },
   "source": [
    "## 2.2 Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPLOIz87EwT0",
    "outputId": "7a50b8f4-0dbe-4096-e9a2-09557686f5fa"
   },
   "outputs": [],
   "source": [
    "# Check on parse job status\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "while True:\n",
    "    result = client.parse.job_status(job_id)\n",
    "    parse_response = result.status\n",
    "    print(f\"Job is {parse_response}\")\n",
    "    if parse_response == \"completed\":\n",
    "        break\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoUKo-Ib-8av"
   },
   "source": [
    "## 2.3 List all jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwWCiaHt-86L",
    "outputId": "f8392e23-7f44-4234-bb58-21238aa0a390"
   },
   "outputs": [],
   "source": [
    "url = f\"{base_url}/parse/jobs\"\n",
    "\n",
    "result = requests.get(url, headers=headers)\n",
    "parse_response = json.loads(result.text)\n",
    "parse_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VasFXM3LFqdQ"
   },
   "source": [
    "## 2.4 Get Job Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UBHttQEFqzz",
    "outputId": "f4428390-38b4-441a-c88e-e6d757802101"
   },
   "outputs": [],
   "source": [
    "results = client.parse.job_results(job_id, output_types=['markdown-per-page'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI429KQi_Dbl"
   },
   "source": [
    "## 2.5 Display 1st Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "cdIeUTzG_Crx",
    "outputId": "bf2a18a8-bc78-43ce-c643-31981ee1219a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(results.pages[0].markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4URev2otqb7j"
   },
   "source": [
    "# 3. Parse UI\n",
    "\n",
    "To see job results in an interactive manner and submit new jobs naviate to the UI using the following link, note you'll need to change `your-tenant-name` to your tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZnKJmvxreYS",
    "outputId": "cc130de5-6279-44a0-bb62-f53ec998a833"
   },
   "outputs": [],
   "source": [
    "tenant = \"your-tenant-name\"\n",
    "print(f\"https://app.contextual.ai/{tenant}/components/parse?job={job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL1feiz9ruM5"
   },
   "source": [
    "![Parse UI](parse-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSwzYe02Hpsq"
   },
   "source": [
    "# 5. Document Hierarchy (Table of Contents)\n",
    "\n",
    "To see the document hierarchy, otherwise known as the table of contents you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "kWFijrNBHpA4",
    "outputId": "a2252b49-ab96-4192-a526-63b3438c009b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(results.table_of_contents.markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z_33Gz7oEUy"
   },
   "source": [
    "# 4. Output Types\n",
    "\n",
    "You can set the desired output format(s) of the parsed file using the `output_types` parameter. Must be `markdown-document`, `markdown-per-page`, and/or `blocks-per-page`. Specify multiple values to get multiple formats in the response:\n",
    "* `markdown-document` parses the whole document into a single concatenated markdown output.\n",
    "* `markdown-per-page` provides markdown output per page.\n",
    "* `blocks-per-page` provides a structured JSON representation of the content blocks on each page, sorted by reading order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6TvInUQHxoH"
   },
   "source": [
    "### 4.1 Display Markdown-per-page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bxOa_7uMHxGE",
    "outputId": "b8aee70d-a1bc-4bf0-c82e-44e69fe95e40"
   },
   "outputs": [],
   "source": [
    "results = client.parse.job_results(job_id, output_types=['markdown-per-page'])\n",
    "\n",
    "for page in results.pages:\n",
    "    display(Markdown(page.markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGqzOlb3JCmx"
   },
   "source": [
    "### 4.2 Blocks per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AKpdj7w2JA0N",
    "outputId": "5af56af8-ed77-4b72-c48f-a9c91daa638d"
   },
   "outputs": [],
   "source": [
    "results = client.parse.job_results(job_id, output_types=['blocks-per-page'])\n",
    "\n",
    "for page in results.pages:\n",
    "    for block in page.blocks:\n",
    "        display(Markdown(block.markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9uw3UlKJE0Y"
   },
   "source": [
    "### 4.3 Markdown-document\n",
    "\n",
    "This returns the document text into a single field `markdown_document`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wq-LiKOIJGTM",
    "outputId": "32159f32-6918-40bd-e7ad-8da4b200c194"
   },
   "outputs": [],
   "source": [
    "result = client.parse.job_results(job_id, output_types=['markdown-document'])\n",
    "\n",
    "display(Markdown(result.markdown_document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJWrTNcUuAeR"
   },
   "source": [
    "# 5. Section Metadata\n",
    "\n",
    "LLMs work best when they're provided with structured information about the document's hierarchy and organization. That's why we've written the parse api to be context aware, i.e. we can include metadata such as which section the text is from.\n",
    "\n",
    "To do this we'll set output_type to `blocks-per-page` and use the parameter `parent_ids` to get the section. In this doc each section has only one parent id however in docs with multiple nesting sections you can have multiple parent id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "89b6OSxwuB0I",
    "outputId": "f61fdf94-1386-4fdf-9528-4079075900ab"
   },
   "outputs": [],
   "source": [
    "result = client.parse.job_results(job_id, output_types=['blocks-per-page'])\n",
    "\n",
    "hash_table = {}\n",
    "\n",
    "for page in result.pages:\n",
    "  for block in page.blocks:\n",
    "    hash_table[block.id] = block.markdown\n",
    "\n",
    "for page in result.pages:\n",
    "  for block in page.blocks:\n",
    "    if block.parent_ids:\n",
    "      parent_content = \"\\n\".join([hash_table[parent_id] for parent_id in block.parent_ids])\n",
    "      display(Markdown(f\"Text\\n======\\n {block.markdown} \\n\\n Section:\\n======\\n{parent_content}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrDZaMCHhaaq"
   },
   "source": [
    "# 6. Table Extraction\n",
    "\n",
    "If we're interested in extracting large tables, sometimes we need to split up those tables to use them in the LLM but preserve table header information across each chunk. To do that we'll use the `enable_split_tables` and `max_split_table_cells` parameters like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eetng879rZq"
   },
   "source": [
    "We're using a document with a large table, you can take a look at the doc [here](https://github.com/ContextualAI/examples/blob/main/03-standalone-api/04-parse/data/omnidocbench-text.pdf).\n",
    "\n",
    "\n",
    "![](table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAmKVGm8mB8y"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/03-standalone-api/04-parse/data/omnidocbench-text.pdf'\n",
    "\n",
    "# Download doc\n",
    "file_path = \"omnidocbench-text_pdf.pdf\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zyAQ8qyAhZpy",
    "outputId": "6026a85f-67bc-4048-9bb3-272527c3864b"
   },
   "outputs": [],
   "source": [
    "file_path = 'omnidocbench-text_pdf.pdf'\n",
    "with open(file_path, \"rb\") as fp:\n",
    "    response = client.parse.create(\n",
    "        raw_file=fp,\n",
    "        parse_mode=\"standard\",\n",
    "        enable_split_tables=True,\n",
    "        max_split_table_cells=50,\n",
    "    )\n",
    "\n",
    "job_id = response.job_id\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eKXQDjChq8Y",
    "outputId": "6bb18aa3-d17e-4bb6-a06c-15d2775af484"
   },
   "outputs": [],
   "source": [
    "# Check on parse job status\n",
    "while True:\n",
    "    result = client.parse.job_status(job_id)\n",
    "    parse_response = result.status\n",
    "    print(f\"Job is {parse_response}\")\n",
    "    if parse_response == \"completed\":\n",
    "        break\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IlBbuBZpuU5e",
    "outputId": "7cfd9d45-12a8-431e-fd36-f569130c8577"
   },
   "outputs": [],
   "source": [
    "result = client.parse.job_results(job_id, output_types=['markdown-per-page'])\n",
    "\n",
    "for page in result.pages:\n",
    "  display(Markdown(page.markdown))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SSwzYe02Hpsq",
    "x6TvInUQHxoH",
    "pGqzOlb3JCmx",
    "P9uw3UlKJE0Y"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
