{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02-H04579t8u"
   },
   "source": [
    "# Using the Contextual AI Document Parser\n",
    "\n",
    "This notebook demonstrates how to use `/parse` with the [Contextual API](https://docs.contextual.ai/api-reference/parse/parse-file) directly and our [Python SDK](https://github.com/ContextualAI/contextual-client-python/tree/main). We'll use the same doc, [Attention is All You Need](https://arxiv.org/pdf/1706.03762) for both. Please see our [blog post](https://contextual.ai/blog/...) for more details on its comparative advantages to other parsers.\n",
    "\n",
    "This notebook has 6 major sections:\n",
    "\n",
    "0. Fetch doc and API key\n",
    "1. REST API implementation\n",
    "2. Contextual SDK\n",
    "3. Parse UI\n",
    "4. Output Types\n",
    "5. Hierarchy Metadata\n",
    "6. Table Extraction\n",
    "\n",
    "You can run this notebook entirely in Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/03-standalone-api/04-parse/parse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE8agDhjA7jq"
   },
   "source": [
    "## 2. Contextual SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwAcEfQ_A-JM",
    "outputId": "844e220b-70c2-41a7-f274-a56cddcae0d2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from contextual import ContextualAI\n",
    "except:\n",
    "  %pip install --upgrade --quiet contextual-client\n",
    "  from contextual import ContextualAI\n",
    "\n",
    "# Setup Contextual Python SDK\n",
    "client = ContextualAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VasFXM3LFqdQ"
   },
   "source": [
    "### 2.4 Get `/parse` Job Results\n",
    "\n",
    "Here i'm fetching `/parse` results for jobs in the UI playground on this tenant:\n",
    "\n",
    "https://app.contextual.ai/akash-contextual-ai/components/parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"55bd4791-560a-46f7-b66f-fbe11bfa8b36\"    # DeepSeek scaling report\n",
    "# job_id = \"2e9c1615-c293-4475-b9d8-f9f6536bdf86\"  # Qwen 3 tech report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UBHttQEFqzz",
    "outputId": "f4428390-38b4-441a-c88e-e6d757802101"
   },
   "outputs": [],
   "source": [
    "parsed_document = client.parse.job_results(job_id, output_types=['markdown-per-page', 'blocks-per-page'])\n",
    "# parsed_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI429KQi_Dbl"
   },
   "source": [
    "### 2.5 Display `/parse` Results\n",
    "\n",
    "The `parsed_document` is a Pydantic model with `.pages` and `.document_metadata` top-level fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(parsed_document.pages[0].markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "cdIeUTzG_Crx",
    "outputId": "bf2a18a8-bc78-43ce-c643-31981ee1219a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Document Hierarchy\n",
       "\n",
       "- Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures [(Page 0)](#insights-into-deepseek-v3-scaling-challenges-and-reflections-on-hardware-for-ai-architectures)\n",
       "  - Abstract [(Page 0)](#abstract)\n",
       "  - CCS Concepts [(Page 0)](#ccs-concepts)\n",
       "  - Keywords [(Page 0)](#keywords)\n",
       "  - ACM Reference Format: [(Page 0)](#acm-reference-format)\n",
       "  - 1 Introduction [(Page 0)](#1-introduction)\n",
       "    - 1.1 Background [(Page 0)](#11-background)\n",
       "    - 1.2 Objectives [(Page 1)](#12-objectives)\n",
       "    - 1.3 Structure of this Paper [(Page 1)](#13-structure-of-this-paper)\n",
       "  - 2 Design Principles for DeepSeek Models [(Page 1)](#2-design-principles-for-deepseek-models)\n",
       "    - 2.1 Memory Efficiency [(Page 1)](#21-memory-efficiency)\n",
       "      - 2.1.1 Low-Precision Models [(Page 1)](#211-low-precision-models)\n",
       "      - 2.1.2 Reducing KV Cache with MLA [(Page 1)](#212-reducing-kv-cache-with-mla)\n",
       "    - 2.2 Cost-Effectiveness of MoE Models [(Page 2)](#22-cost-effectiveness-of-moe-models)\n",
       "    - 2.3 Increasing Inference Speed [(Page 3)](#23-increasing-inference-speed)\n",
       "    - 2.4 Technique Validation Methodology [(Page 4)](#24-technique-validation-methodology)\n",
       "  - 3 Low-Precision Driven Design [(Page 4)](#3-low-precision-driven-design)\n",
       "    - 3.1 FP8 Mix-Precision Training [(Page 4)](#31-fp8-mix-precision-training)\n",
       "    - 3.2 LogFMT: Communication Compression [(Page 5)](#32-logfmt-communication-compression)\n",
       "  - 4 Interconnection Driven Design [(Page 5)](#4-interconnection-driven-design)\n",
       "    - 4.1 Current Hardware Architecture [(Page 5)](#41-current-hardware-architecture)\n",
       "    - 4.2 Hardware-Aware Parallelism [(Page 5)](#42-hardware-aware-parallelism)\n",
       "    - 4.3 Model Co-Design: Node-Limited Routing [(Page 6)](#43-model-co-design-node-limited-routing)\n",
       "    - 4.4 Scale-Up and Scale-Out Convergence [(Page 6)](#44-scale-up-and-scale-out-convergence)\n",
       "      - 4.4.1 Limitations of Current Implementations [(Page 6)](#441-limitations-of-current-implementations)\n",
       "      - 4.4.2 Suggestions [(Page 6)](#442-suggestions)\n",
       "    - 4.5 Bandwidth Contention and Latency [(Page 7)](#45-bandwidth-contention-and-latency)\n",
       "  - 5 Large Scale Network Driven Design [(Page 7)](#5-large-scale-network-driven-design)\n",
       "    - 5.1 Network Co-Design: Multi-Plane Fat-Tree [(Page 7)](#51-network-co-design-multi-plane-fat-tree)\n",
       "    - 5.2 Low Latency Networks [(Page 8)](#52-low-latency-networks)\n",
       "  - 6 Discussion and Insights for Future Hardware Architecture Design [(Page 10)](#6-discussion-and-insights-for-future-hardware-architecture-design)\n",
       "    - 6.1 Robustness Challenges [(Page 10)](#61-robustness-challenges)\n",
       "    - 6.2 CPU Bottlenecks and Interconnects [(Page 10)](#62-cpu-bottlenecks-and-interconnects)\n",
       "    - 6.3 Toward Intelligent Networks for AI [(Page 10)](#63-toward-intelligent-networks-for-ai)\n",
       "    - 6.4 Discussion on Memory-Semantic Communication and Ordering Issue [(Page 11)](#64-discussion-on-memory-semantic-communication-and-ordering-issue)\n",
       "    - 6.5 In-Network Computation and Compression [(Page 11)](#65-in-network-computation-and-compression)\n",
       "    - 6.6 Memory-Centric Innovations [(Page 11)](#66-memory-centric-innovations)\n",
       "      - 6.6.1 Limitations of Memory Bandwidth [(Page 11)](#661-limitations-of-memory-bandwidth)\n",
       "      - 6.6.2 Suggestions: [(Page 11)](#662-suggestions)\n",
       "  - 7 Conclusion [(Page 11)](#7-conclusion)\n",
       "  - References [(Page 12)](#references)\n",
       "  - References [(Page 13)](#references)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# human readable markdown version of .document_metadata.hierarchy.blocks \n",
    "display(Markdown(parsed_document.document_metadata.hierarchy.table_of_contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect a particular hierarchy heading node \"### 1.2 Objectives\", note the structure with `.id`, `.parent_ids`, `.markdown`, `.page_index` and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentMetadataHierarchyBlock(id='9f6de97d-ce68-1ecf-a589-df984eb75d6a', bounding_box=DocumentMetadataHierarchyBlockBoundingBox(x0=0.08790523553985397, x1=0.21134562274209814, y0=0.10427671490293561, y1=0.12276158188328598), markdown='### 1.2 Objectives', type='heading', confidence_level=None, hierarchy_level=2, page_index=1, parent_ids=['a30ad33b-eb79-1e24-f714-b65521d53876', '56e22499-de21-20c0-ef93-4ed41f58e85a'])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsed_document.document_metadata.hierarchy.blocks\n",
    "parsed_document.document_metadata.hierarchy.blocks[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-navigable document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedDocumentForAgent:\n",
    "    \"\"\"\n",
    "    This class wraps `/parse` output exposing tool functions allowing an LLM agent to \n",
    "    navigate and interact with the parsed document.\n",
    "\n",
    "    0. read_document() -> str\n",
    "    1. read_hierarchy() -> str, list[dict[id, level, markdown, page_index]]\n",
    "    2. read_pages(page_indexes) -> str\n",
    "    3. read_hierarchy_section(heading_block_id) -> str\n",
    "    \"\"\"\n",
    "    def __init__(self, parsed_document):\n",
    "        self.parsed_document = parsed_document\n",
    "        self.block_map = {block.id: block for page in self.parsed_document.pages for block in page.blocks}\n",
    "        self.heading_block_map = {block.id: block for block in self.parsed_document.document_metadata.hierarchy.blocks}\n",
    "    \n",
    "    def read_document(self) -> str:\n",
    "        \"\"\"\n",
    "        Read contents of the entire document as markdown (may be large)\n",
    "        \"\"\"\n",
    "        return self.parsed_document.markdown_document\n",
    "    \n",
    "    def read_hierarchy(self) -> tuple[str, list[dict]]:\n",
    "        \"\"\"\n",
    "        Read the outline structure of the document as:\n",
    "            (i) human/LLM readable markdown nested list\n",
    "            (ii) LLM referenceable list of structured dicts\n",
    "\n",
    "        Could provide either (ii) or both as context to an LLM to navigate the document and reference specific sections\n",
    "        \"\"\"\n",
    "        hierarchy_markdown = self.parsed_document.document_metadata.hierarchy.table_of_contents\n",
    "\n",
    "        hierarchy_list = []\n",
    "        for block in self.parsed_document.document_metadata.hierarchy.blocks:\n",
    "            hierarchy_list.append({\n",
    "                \"block_id\": block.id, # might need to translate the uuid to a LLM-friendly integer index instead\n",
    "                \"hierarchy_level\": block.hierarchy_level,\n",
    "                \"markdown\": block.markdown,\n",
    "                \"page_index\": block.page_index\n",
    "            })\n",
    "        return hierarchy_markdown, hierarchy_list\n",
    "    \n",
    "    def read_pages(self, page_indexes: list[int]) -> str:\n",
    "        \"\"\"\n",
    "        Read the contents of the document for the provided page indexes\n",
    "        \"\"\"\n",
    "        page_separator = \"\\n\\n---\\nPage index: {page_index}\\n\\n\"\n",
    "        content = \"\"\n",
    "        for page_index in page_indexes:\n",
    "            content += page_separator.format(page_index=page_index) + self.parsed_document.pages[page_index].markdown\n",
    "        return content\n",
    "        \n",
    "    def read_hierarchy_section(self, heading_block_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Read the contents of the document that are children of the given heading block referenced by `heading_block_id`\n",
    "        \"\"\"\n",
    "        heading_block = self.heading_block_map[heading_block_id]\n",
    "        parent_path_prefix = heading_block.parent_ids + [heading_block_id]\n",
    "\n",
    "        section_blocks = []\n",
    "        for page in self.parsed_document.pages:\n",
    "            for block in page.blocks:\n",
    "                # filter for blocks that share the same parent path\n",
    "                if block.parent_ids[:len(parent_path_prefix)] == parent_path_prefix:\n",
    "                    section_blocks.append(block)\n",
    "        \n",
    "        section_content = \"\\n\".join([block.markdown for block in section_blocks])\n",
    "        return section_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigable_document = ParsedDocumentForAgent(parsed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1.2 Objectives\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DocumentMetadataHierarchyBlock(id='9f6de97d-ce68-1ecf-a589-df984eb75d6a', bounding_box=DocumentMetadataHierarchyBlockBoundingBox(x0=0.08790523553985397, x1=0.21134562274209814, y0=0.10427671490293561, y1=0.12276158188328598), markdown='### 1.2 Objectives', type='heading', confidence_level=None, hierarchy_level=2, page_index=1, parent_ids=['a30ad33b-eb79-1e24-f714-b65521d53876', '56e22499-de21-20c0-ef93-4ed41f58e85a'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# block_id = \"9f6de97d-ce68-1ecf-a589-df984eb75d6a\"\n",
    "heading_block = parsed_document.document_metadata.hierarchy.blocks[7]\n",
    "heading_block_id = heading_block.id\n",
    "\n",
    "print(heading_block.markdown)\n",
    "heading_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This paper does not aim to reiterate the detailed architectural and algorithmic specifics of DeepSeek-V3, which are extensively documented in its technical report [26]. Instead, it adopts a dual perspective—spanning hardware architecture and model design—to explore the intricate interplay between them in achieving cost-efficient large-scale training and inference. By examining this synergy, we aim to provide actionable insights for scaling LLMs efficiently without sacrificing performance or accessibility.\n",
       "Specifically, the paper focuses on:\n",
       "- Hardware-Driven Model Design: Analyze how hardware features, such as FP8 low-precision computation and scale-up/scale-out network properties, informed the architectural choices in DeepSeek-V3.\n",
       "- Mutual Dependencies Between Hardware and Models: Investigate how hardware capabilities shape model innovation and how the evolving demands of LLMs drive the need for next-generation hardware.\n",
       "- Future Directions for Hardware Development: Derive actionable insights from DeepSeek-V3 to guide the co-design of future hardware and model architectures, paving the way for scalable, cost-efficient AI systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navigated_markdown = navigable_document.read_hierarchy_section(heading_block_id)\n",
    "\n",
    "Markdown(navigated_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigated_markdown = navigable_document.read_pages([0, 1])\n",
    "\n",
    "Markdown(navigated_markdown)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SSwzYe02Hpsq",
    "x6TvInUQHxoH",
    "pGqzOlb3JCmx",
    "P9uw3UlKJE0Y"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sunrise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
