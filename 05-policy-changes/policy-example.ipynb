{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iPJnDH0HhXB"
   },
   "source": [
    "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Image description\" width=\"160\" />\n",
    "\n",
    "<br/>\n",
    "\n",
    "# Tracking Changes in Long Policy Documents Using Contextual AI\n",
    "\n",
    "Contextual AI lets you create and use generative AI agents. This notebook introduces an example for analyzing complex policy documents and their evolution over time. These RAG Agents overcome traditional challenges of analyzing lengthy documents and identifying policy changes across multiple versions.\n",
    "\n",
    "This notebook covers the following steps:\n",
    "- Creating a Datastore\n",
    "- Ingesting Documents\n",
    "- Creating an RAG Agent\n",
    "- Querying an RAG Agent\n",
    "\n",
    "With the exception of the tuning model, the rest of the notebook can be run in under 15 minutes. \n",
    "The full documentation is available at [docs.contextual.ai](https://docs.contextual.ai/)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/05-policy-changes/policy-example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install contextual-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "from IPython.display import display, JSON\n",
    "import pandas as pd\n",
    "from contextual import ContextualAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4wJG66VTIQvO"
   },
   "outputs": [],
   "source": [
    "#Setup API key\n",
    "#os.environ[\"CONTEXTUAL_API_KEY\"] = API_KEY  # You can store the API key is stored as the environment variable \n",
    "\n",
    "client = ContextualAI(\n",
    "    api_key=\"CONTEXTUAL_API_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the files into the local environment if you don't have them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_file(filepath):\n",
    "    # Ensure the directory exists before writing the file\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Fetching {filepath}\")\n",
    "        url = f\"https://raw.githubusercontent.com/ContextualAI/examples/main/05-policy-changes/{filepath}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved {filepath}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch {filepath}. HTTP status code: {response.status_code}\")\n",
    "\n",
    "fetch_file('data/FEMA_v2_2017.pdf')\n",
    "fetch_file('data/FEMA_v3.1_2018.pdf')\n",
    "fetch_file('data/FEMA_v4_2020.pdf')\n",
    "fetch_file('/FEMA_2025_updates.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcqh_-j1MzCn"
   },
   "source": [
    "## Step 1: Create your Datastore\n",
    "\n",
    "\n",
    "You will need to first create a datastore for your agent using the  /datastores endpoint. A datastore is a secure storage for data. Each agent will have its own datastore for storing data securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlulbIvjdbZA",
    "outputId": "7029ff7d-193a-4cf1-98e8-0e29451ec446"
   },
   "outputs": [],
   "source": [
    "result = client.datastores.create(name=\"Demo_FEMA\")\n",
    "datastore_id = result.id\n",
    "print(f\"Datastore ID: {datastore_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IkAep8Vf29_"
   },
   "source": [
    "## Step 2: Ingest Documents into your Datastore\n",
    "\n",
    "You can now ingest documents into your Agent's datastore using the /datastores endpoint. Documents must be a PDF or HTML file.\n",
    "\n",
    "I am wrapping the ingest function in a wrapper to upload all the PDF and HTML files in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_documents(folder_path, datastore_id) -> Dict[str, str]:\n",
    "    folder = Path(folder_path)\n",
    "    document_ids = {}  # Dictionary to store filename: document_id pairs\n",
    "    \n",
    "    for file_path in folder.iterdir():\n",
    "        if file_path.is_file() and file_path.suffix.lower() in ['.pdf', '.html']:\n",
    "            try:\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    ingestion_result = client.datastores.documents.ingest(datastore_id, file=f)\n",
    "                    document_ids[file_path.name] = ingestion_result.id\n",
    "                    print(f\"Successfully uploaded {file_path.name} to datastore {datastore_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {file_path.name}: {str(e)}\")\n",
    "    \n",
    "    return document_ids\n",
    "\n",
    "# Usage example\n",
    "folder_path = 'data'\n",
    "uploaded_docs = ingest_documents(folder_path, datastore_id)\n",
    "\n",
    "# Now you can access the document IDs like this:\n",
    "for filename, doc_id in uploaded_docs.items():\n",
    "    print(f\"File: {filename} -> Document ID: {doc_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mZdyD5cK8lc"
   },
   "source": [
    "Once ingested, you can view the list of documents, see their metadata, and also delete documents. The dictionary `uploaded_docs` has the document IDs.\n",
    "These are very large files, so don't be surprised if it takes a few minutes to finish processing. I have included a simple script for monitoring the progress.  In the meantime you can create the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j78jlN1_lIbM"
   },
   "outputs": [],
   "source": [
    "metadata_status = {}\n",
    "\n",
    "# Loop through each document in uploaded_docs\n",
    "for filename, doc_id in uploaded_docs.items():\n",
    "    try:\n",
    "        metadata = client.datastores.documents.metadata(\n",
    "            datastore_id=datastore_id,\n",
    "            document_id=doc_id\n",
    "        )\n",
    "        metadata_status[filename] = metadata.status\n",
    "        print(f\"Document: {filename}\")\n",
    "        print(f\"Status: {metadata.status}\")\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting metadata for {filename}: {str(e)}\")\n",
    "        metadata_status[filename] = \"error\"\n",
    "\n",
    "# Print summary of all document statuses\n",
    "print(\"\\nSummary of document processing status:\")\n",
    "for filename, status in metadata_status.items():\n",
    "    print(f\"{filename}: {status}\")\n",
    "\n",
    "# Check if all documents are ready\n",
    "all_ready = all(status == \"complete\" for status in metadata_status.values())\n",
    "print(f\"\\nAll documents ready: {'Yes' if all_ready else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcTyR5QeHw7z"
   },
   "source": [
    "## Step 3: Create your Agent\n",
    "\n",
    "Next let's create the Agent and modify it to our needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr4jmjF_LtTp"
   },
   "source": [
    "Some additional parameters include setting a system prompt or using a previously tuned model.\n",
    "\n",
    "`system_prompt` is used for the instructions that your RAG agent references when generating responses. Note that we do not guarantee that the system will follow these instructions exactly.\n",
    "\n",
    "Here I have modified the system prompt to keep in mind differences and versions for the documents. It is expected for you to modify the system prompt for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "r5jsWXpBPLtx"
   },
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You are an analyst focused on identifying differences across documents. V4 was published in 2020, V3.1 was published in 2018 and V2 was published in 2017. If retrieved, V5 is proposed for 2025. When discussing policy keep in mind the version and consider differences in other versions. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymCcfHR1Lra6",
    "outputId": "310369a2-90a6-4b40-e3f1-fcc90f117d2f"
   },
   "outputs": [],
   "source": [
    "app_response = client.agents.create(\n",
    "    name=\"Demo-PolicyChanges\",\n",
    "    description=\"Agent to identify policy changes in FEMA documents\",\n",
    "    system_prompt=system_prompt,\n",
    "    datastore_ids=[datastore_id]\n",
    ")\n",
    "agent_id= app_response.id\n",
    "print(f\"Agent ID created: {agent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFq4oMe9gMuz"
   },
   "source": [
    "## Step 4: Query your Agent\n",
    "\n",
    "Let's query our agent to see if its working. The required information is the agent_id and messages.  \n",
    "\n",
    "A good starting query for this use case is how has cost eligibility changed. This shows how the model works across multiple large documents and can track changes between the documents.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOW94UdMySbp"
   },
   "source": [
    "**Note:** It may take a few minutes for the document to be ingested and processed. The Assistant will give a detailed answer once the documents are ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask it about cost elibigilbity changes. (Even though this question doesn't include a question mark, the agent answers the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wE4d616-rseT",
    "outputId": "dc58d319-0ef6-4d2a-ea30-5d2d8e109db3"
   },
   "outputs": [],
   "source": [
    "query_result = client.agents.query.create(\n",
    "    agent_id=agent_id,\n",
    "    messages=[{\n",
    "        \"content\": \"How has cost eligibility changed since 2017\",\n",
    "        \"role\": \"user\"\n",
    "    }]\n",
    ")\n",
    "print(query_result.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another question that show the comparison and it's great to look at the retrieved results is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = client.agents.query.create(\n",
    "    agent_id=agent_id,\n",
    "    messages=[{\n",
    "        \"content\": \"What's changed with the Small Business Administration Loan Requirement\",\n",
    "        \"role\": \"user\"\n",
    "    }]\n",
    ")\n",
    "print(query_result.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is just the start. You can continue asking more queries from the API or use the UI to try more queries. Everything you do in the UI, there are APIs for. Check out [docs.contextual.ai](https://docs.contextual.ai/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking to the UI\n",
    "tenant=\"\" # put the name of your tenant here\n",
    "print(f\"Click on this link to query your Agent: https://app.contextual.ai/{tenant}/agents/{agent_id}/chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some further queries to show off how this RAG Agent tracks changes over time:\n",
    "\n",
    "Query:\n",
    "- What's changed with the Small Business Administration Loan Requirement   \n",
    "- How has the relationship to indian tribal governments changed\n",
    "\n",
    "The agent can also help generate insights based on changes, try these queries:\n",
    "\n",
    "- How has the appeals process changed  \n",
    "- Based on the appeal changes in version 4, how should we change our contracts with experts\n",
    "\n",
    "To see how the RAG agent responds to new information, add the [FEMA_2025_updates]('FEMA_2025_updates.pdf') to the datastore. This is a synthetic update to show that the agent responds to new information. After loading in the datastore, try the query:\n",
    "\n",
    "- How has cost eligibility changed since 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKAmujbKgUBj"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "In this Notebook, we've created a RAG agent showing changes in FEMA policy. You browse more examples here or learn more at [docs.contextual.ai](https://docs.contextual.ai/). Finally, reach out to your account team if you have further questions or issues."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
