{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPJnDH0HhXB"
      },
      "source": [
        "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Image description\" width=\"160\" />\n",
        "\n",
        "<br/>\n",
        "\n",
        "# Specialization Deep Dive\n",
        "\n",
        "This notebook provides a deep dive on specializing or improving your Contextual AI agents. It focuses on showing you the specific settings, but to dive deeper into the usefulness of the settings, please consult full documentation available at [docs.contextual.ai](https://docs.contextual.ai/)\n",
        "\n",
        "This notebook covers the following steps:\n",
        "- Queries / Retrieval\n",
        "- Evaluation with LMUnit\n",
        "- Modifying System Prompt\n",
        "- Datastore Filter\n",
        "- Retrieval Settings\n",
        "- Filter Model / Prompt\n",
        "- Generation Settings\n",
        "\n",
        "For getting usage data and agent feedback, check out example using the metrics API in the [quick start notebook](https://github.com/ContextualAI/examples/tree/main/01-getting-started/quick-start.ipynb).\n",
        "\n",
        "\n",
        "The notebook requires you to first build an agent going through the [getting started](https://github.com/ContextualAI/examples/tree/main/01-getting-started) or the [hands on lab](https://github.com/ContextualAI/examples/tree/main/02-hands-on-lab).\n",
        "\n",
        "To run this notebook interactively, you can open it in Google Colab.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/06-improve-agent-performance/improvement-overview.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install contextual-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "cim9P99PQP1w",
        "outputId": "d87bf3f4-b624-4e95-fb74-dc71a1ef5b9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "from IPython.display import display, JSON\n",
        "import pandas as pd\n",
        "from contextual import ContextualAI\n",
        "import ast\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modify this with your API key, for best practices use environment variables and don't hardcode your API key\n",
        "API_KEY = os.environ[\"CONTEXTUAL_API_KEY\"]\n",
        "client = ContextualAI(api_key = API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84FKJtqnQt3x"
      },
      "source": [
        "Load up the files you will need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUk8u_lSOArL",
        "outputId": "a79c80a1-5772-4078-e32b-b58119fd32dd"
      },
      "outputs": [],
      "source": [
        "def fetch_file(filepath):\n",
        "    if not os.path.exists(os.path.dirname(filepath)):  # Ensure the directory exists\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)  # Create if not exists\n",
        "\n",
        "    print(f\"Fetching {filepath}\")\n",
        "    response = requests.get(f\"https://raw.githubusercontent.com/ContextualAI/examples/main/01-getting-started/{filepath}\")\n",
        "\n",
        "    with open(filepath, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "fetch_file('data/eval_short.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFq4oMe9gMuz"
      },
      "source": [
        "## 1: Queries and Retrievals\n",
        "\n",
        "A first step to understanding our agent is passing it queries. Contextual AI will return a response.\n",
        "\n",
        "Besides the model response, it's also possible to retrieve the full text of all the attributions/citations. You can also retrieve images of the bounding boxes for attributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFhZ-h3vSi2l"
      },
      "source": [
        "Let's start with the prebuilt agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvlwoXzSQP1w"
      },
      "outputs": [],
      "source": [
        "agent_id = 'YOUR_AGENT_ID'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVa5n-_9Sop-"
      },
      "source": [
        "The query here also includes the optional parameter for including the retrieval contexts. Normally, you would set this to false for faster retrieval. However, here I wanted to show you the full text of information available to developers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bvc2MkpDQP1x"
      },
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        # Input your question here\n",
        "        \"content\": \"Tell about Apple's sales\",\n",
        "        \"role\": \"user\"\n",
        "    }],\n",
        "    include_retrieval_content_text = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I can now see the results of the query. If you are using the financial RAG agent with the Apple 10-Q, you some formated markdown with sales by product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "content = query_result.message.content\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOmbhFiaIAX"
      },
      "source": [
        "Here I show the first document retrieved that was relevant to the query. If you are using the financial RAG agent with the Apple 10-Q, you should see a text chunk devoted to Apple's product sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR-rCnf5QP1x"
      },
      "outputs": [],
      "source": [
        "context_text = query_result.retrieval_contents[3].content_text\n",
        "print(context_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For getting usage data and agent feedback, check out example using the metrics API in the [quick start notebook](https://github.com/ContextualAI/examples/tree/main/01-getting-started/quick-start.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VTZGxEMQP1x"
      },
      "source": [
        "## 2: Running Evaluation Jobs\n",
        "\n",
        "Contextual AI offers the ability to run natural language unit tests (LMUnit)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59LCCn_WQP1z"
      },
      "source": [
        "### 2.1 LMUnit\n",
        "\n",
        "The `lmunit` endpoint supports natural language unit tests. To learn more, check out the [blog post](https://contextual.ai/blog/lmunit/) or check out a [notebook using LMUnit](https://github.com/ContextualAI/examples/tree/main/03-lmunit).\n",
        "Here is a simple example of natural langauge unit test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnC-RTJUVMRA"
      },
      "outputs": [],
      "source": [
        "response = client.lmunit.create(\n",
        "                    query=\"What material is used in N95 masks?\",\n",
        "                    response=\"N95 masks are made primarily of polypropylene. This synthetic material is created through a melt-blowing process that creates multiple layers of microfibers. The material was chosen because it can be electrostatically charged to attract particles. Particles are the constituents of the universe\",\n",
        "                    unit_test=\"Does the response avoid unnecessary information?\"\n",
        "                )\n",
        "print(response.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output there will be a numerical score on a scale of 1 to 5.\n",
        "The low score here, `2.065`, makes sense given the long response filled with excess information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWWt707mQP1z"
      },
      "source": [
        "## 3: Modifying the System Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY5i_pFDVZIj"
      },
      "source": [
        "After initial testing, you may want to revise the system prompt. Here I have an updated prompt with additional information in the critical guidelines section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xi_cliANQP1z"
      },
      "outputs": [],
      "source": [
        "system_prompt2 = '''\n",
        "You are an AI assistant specialized in financial analysis and reporting. Your responses should be precise, accurate, and sourced exclusively from official financial documentation provided to you. Please follow these guidelines:\n",
        "\n",
        "Data Analysis & Response Quality:\n",
        "* Only use information explicitly stated in provided documentation (e.g., earnings releases, financial statements, investor presentations)\n",
        "* Present comparative analyses using structured formats with tables and bullet points where appropriate\n",
        "* Include specific period-over-period comparisons (quarter-over-quarter, year-over-year) when relevant\n",
        "* Maintain consistency in numerical presentations (e.g., consistent units, decimal places)\n",
        "* Flag any one-time items or special charges that impact comparability\n",
        "\n",
        "\n",
        "For any analysis, provide comprehensive insights using all relevant available information while maintaining strict adherence to these guidelines and focusing on delivering clear, actionable information.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARpHSA3dViKG"
      },
      "source": [
        "Let's now update the agent and verify the changes by checking the agent metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASRr5EPsQP1z"
      },
      "outputs": [],
      "source": [
        "client.agents.update(agent_id=agent_id, system_prompt=system_prompt2)\n",
        "\n",
        "agent_config = client.agents.metadata(agent_id=agent_id)\n",
        "print (agent_config.system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yai7YC3KVmDD"
      },
      "source": [
        "Modifying the system prompt is useful when trying to improve the response generation. For example, by making it more concise, more professional, or including specific terms that should be part of the response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4: Datastore Filter\n",
        "\n",
        "Document metadata can be used to limit documents included for retrieval. This section shows how to add custom metadata to documents and how to filter them. \n",
        "Typical use cases for this include, when a query should use a subset of documents, for example a specific company in a datastore that contains multiple companies financial documents. Other examples are specifying a specific year or product name. \n",
        "Let's walk through adding metadata to a document and then doing a filtering action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by adding metadata. Please be aware, metadata is case sensitive. This example is based on the financial RAG use case with the Apple.pdf document. Add the datastore and document information for the Apple.pdf below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datastore_id = 'datastore_id'\n",
        "document_id = 'dat_id'\n",
        "result = client.datastores.documents.set_metadata(datastore_id=datastore_id, \n",
        "                        document_id=document_id, \n",
        "                        custom_metadata={\"Company\": \"Apple\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see the new custom metadata field by viewing the document's metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata = client.datastores.documents.metadata(datastore_id = datastore_id, \n",
        "                        document_id = document_id)\n",
        "print(\"Document metadata:\", metadata.custom_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use the document filtering. Let's first query the agent and make sure we are getting a response. What is included in the filter is what passes through to the retrieval stage. Here are three variations:\n",
        "- no filtering, \n",
        "- with filtering that includes the Apple document based on metadata\n",
        "- filtering that excludes the Apple document  \n",
        "\n",
        "Also remember, the values are case sensitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"what was the sales for Apple\",\n",
        "        \"role\": \"user\"\n",
        "    }],\n",
        ")\n",
        "print(query_result.message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"what was the sales for Apple\",\n",
        "        \"role\": \"user\"\n",
        "    }],\n",
        "    documents_filters= {\n",
        "        \"operator\": \"AND\",\n",
        "        \"filters\": [\n",
        "            {\"field\": \"Company\", \"operator\": \"equals\", \"value\": \"apple\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "print(query_result.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You see results here, because have included the Apple.pdf document based on metadata. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"what was the sales for Apple\",\n",
        "        \"role\": \"user\"\n",
        "    }],\n",
        "    documents_filters= {\n",
        "        \"operator\": \"AND\",\n",
        "        \"filters\": [\n",
        "            {\"field\": \"Company\", \"operator\": \"equals\", \"value\": \"Nike\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "print(query_result.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the agent is not able to respond properly to the sales query. The document filtering here is filtering out the Apple.pdf, because it does not have the value of  Nike in the metadata field."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uLIXp51QP1z"
      },
      "source": [
        "## 5: Retrieval Settings\n",
        "\n",
        "There are a number of settings available for modifying retrieval settings. These are advanced parameters, for most users you will get good results from leaving these as platform defaults.  For more detail on the advanced settings, please refer to the [documentation](https://docs.contextual.ai/).\n",
        "\n",
        "At the global level:\n",
        "- enable_rerank: Enable/disable the use of the reranker model\n",
        "- enable_filter: The filter is a capability in the platform to remove irrelevant or low-quality information before it's used to generate responses.\n",
        "- enable_multi_turn: This feature is experimental and will be improved.\n",
        "\n",
        "Retriever settings\n",
        "- top_k_retrieved_chunks: The number of chunks retrieved at the retriever stage\n",
        "- lexical_alpha: This parameter controls how much weight is given to exact keyword matches when searching through documents.\n",
        "- semantic_alpha: This parameter controls the weight given to semantic search. The total of lexical and semantic should sum to 1.\n",
        "\n",
        "Reranker settings\n",
        "- top_k_reranked_chunks: The number of chunks returned at the reranker stage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rUpThueoQP1z"
      },
      "outputs": [],
      "source": [
        "# Simple update focusing on retrieval parameters\n",
        "response = client.agents.update(\n",
        "    agent_id=agent_id,\n",
        "    extra_body={\n",
        "        \"agent_configs\": {\n",
        "            \"retrieval_config\": {\n",
        "                \"top_k_retrieved_chunks\": 10,\n",
        "                \"lexical_alpha\": 0.5,\n",
        "                \"semantic_alpha\": 0.5\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1ghsGvaxQP1z"
      },
      "outputs": [],
      "source": [
        "# Update focusing on filtering and reranking\n",
        "response = client.agents.update(\n",
        "    agent_id=agent_id,\n",
        "    extra_body={\n",
        "        \"agent_configs\": {\n",
        "            \"filter_and_rerank_config\": {\n",
        "                \"top_k_reranked_chunks\": 5\n",
        "            },\n",
        "            \"global_config\": {\n",
        "                \"enable_rerank\": True,\n",
        "                \"enable_filter\": True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz6AH2j5X8vY"
      },
      "source": [
        "Get the agent metadata that will show the retrieval changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_info = client.agents.metadata(agent_id=agent_id)\n",
        "print(agent_info.agent_configs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Zuf8DGSVYCM9"
      },
      "outputs": [],
      "source": [
        "# Complete configuration update using all available parameters -- you shouldn't need to change all of these\n",
        "response = client.agents.update(\n",
        "    agent_id=agent_id,\n",
        "    extra_body={\n",
        "        \"agent_configs\": {\n",
        "            \"retrieval_config\": {\n",
        "                \"top_k_retrieved_chunks\": 10,\n",
        "                \"lexical_alpha\": 0.5,\n",
        "                \"semantic_alpha\": 0.5\n",
        "            },\n",
        "            \"filter_and_rerank_config\": {\n",
        "                \"top_k_reranked_chunks\": 5\n",
        "            },\n",
        "            \"global_config\": {\n",
        "                \"enable_rerank\": True,\n",
        "                \"enable_filter\": True,\n",
        "                \"enable_multi_turn\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6: Filter Model / Prompt \n",
        "\n",
        "Filter prompts are used to reduce or filter the retrieved documents flowing to the Contextual AI Grounded Language Model (GLM). Specifically, it filters documents coming out of the reranker and prior to the GLM. For background, the flow of retrieved documents is: Retrievers --> Rerank --> Filter Prompt --> GLM\n",
        "\n",
        "A filter prompt is helpful for selecting relevant documents from a larger pool of documents. For example, \"if a query mentions a date, only select docs from within 6 months of that date\" or \"if a query mentions <customer-specific term>, exclude all docs without that term\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_prompt = \"Always reply with no\"\n",
        "client.agents.update(agent_id=agent_id, filter_prompt=filter_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's verify the filter prompt has been modified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_config = client.agents.metadata(agent_id=agent_id)\n",
        "print (agent_config.filter_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This filter prompt will refuse to answer for this example. We can verify that with a new query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"what was the sales for Apple in 2022\",\n",
        "        \"role\": \"user\"\n",
        "    }]\n",
        ")\n",
        "print(query_result.message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Remove the filter prompt, so we can keep using the agent in this notebook\n",
        "filter_prompt = \"\"\n",
        "\n",
        "client.agents.update(agent_id=agent_id, filter_prompt=filter_prompt)\n",
        "\n",
        "agent_config = client.agents.metadata(agent_id=agent_id)\n",
        "print (agent_config.filter_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXfZf3SnQP10"
      },
      "source": [
        "## 7: Generation Settings\n",
        "\n",
        "There are a number of settings available for modifying the generation of responses. These are advanced settings, please refer to the documentation for more settings and details.\n",
        "\n",
        "- max_new_tokens\n",
        "- temperature\n",
        "- top_p\n",
        "- frequency_penalty\n",
        "- seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9KaBgYPaQP10"
      },
      "outputs": [],
      "source": [
        "# Update focusing on generation parameters\n",
        "response = client.agents.update(\n",
        "    agent_id=agent_id,\n",
        "    extra_body={\n",
        "        \"agent_configs\": {\n",
        "            \"generate_response_config\": {\n",
        "                \"max_new_tokens\": 500,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.95,\n",
        "                \"frequency_penalty\": 0.5,\n",
        "                \"seed\": 42\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRLX7QlAQP10"
      },
      "outputs": [],
      "source": [
        "agent_info = client.agents.metadata(agent_id=agent_id)\n",
        "print(agent_info.agent_configs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
