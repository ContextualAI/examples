{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuGiPEPWsZ1J"
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://imagedelivery.net/Dr98IMl5gQ9tPkFM5JRcng/3e5f6fbd-9bc6-4aa1-368e-e8bb1d6ca100/Ultra\" alt=\"Contextual AI Logo\" width=\"160\" />\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "# RAG Agent Monitoring & Analytics Dashboard\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use the **Contextual AI Metrics API** to monitor, analyze, and optimize Retrieval-Augmented Generation (RAG) agents in production. It covers methods for tracking performance metrics, analyzing user feedback, and assessing system health to ensure consistent, high-quality responses.\n",
    "\n",
    "### What is Covered\n",
    "\n",
    "- **Real-time Metrics Collection**: Access conversation data and user feedback\n",
    "- **Performance Analytics**: Analyze response quality, user satisfaction, and system usage patterns\n",
    "- **Time Series Analysis**: Visualize performance over time\n",
    "- **Quality Monitoring**: Examine feedback distributions, flagged responses, and other quality indicators\n",
    "- **Operational Insights**: Identify usage peaks and engagement patterns\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- **Contextual AI Account**: Active subscription with API access\n",
    "- **API Key**: Valid API key with metrics access permissions\n",
    "- **Python Environment**: Python 3.8+ with required dependencies\n",
    "- **Active RAG Agent**: At least one deployed agent with conversation history\n",
    "\n",
    "You can run this notebook entirely in Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/14-monitoring/monitoring_intro.ipynb)\n",
    "     \n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Contextual AI Documentation](https://docs.contextual.ai/)\n",
    "- [API Reference](https://docs.contextual.ai/api-reference/datastores/list-datastores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxVTP8rWsZ1L"
   },
   "source": [
    "## Environment Setup & Configuration\n",
    "\n",
    "### API Key Configuration\n",
    "\n",
    "To access the Metrics API, you'll need a valid Contextual AI API key:\n",
    "\n",
    "1. **Generate API Key**: Log into your tenant at [app.contextual.ai](https://app.contextual.ai)\n",
    "2. **Navigate to API Keys**: Go to Settings ‚Üí API Keys\n",
    "3. **Create New Key**: Click \"Create API Key\" and copy the generated key\n",
    "4. **Secure Storage**: Store your key securely using environment variables\n",
    "\n",
    "### Required Dependencies\n",
    "\n",
    "Install the necessary packages for data analysis and visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThWd0CH_sZ1L"
   },
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install contextual-client pandas plotly matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0IF54vSsZ1M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "from IPython.display import display, JSON\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from contextual import ContextualAI\n",
    "\n",
    "# Set display options for better notebook experience\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm7AXFu_sZ1M"
   },
   "outputs": [],
   "source": [
    "# Initialize Contextual AI client\n",
    "# Option 1: Use environment variable (recommended)\n",
    "# os.environ[\"CONTEXTUAL_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Direct initialization (for demo purposes)\n",
    "client = ContextualAI(\n",
    "    api_key=os.environ[\"CONTEXTUAL_API_KEY\"]\n",
    ")\n",
    "\n",
    "print(\"Contextual AI client initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBaI3CfNNHqo"
   },
   "outputs": [],
   "source": [
    "def fetch_file(filepath):\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True) if '/' in filepath else None\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Fetching {filepath}\")\n",
    "        response = requests.get(f\"https://raw.githubusercontent.com/ContextualAI/examples/main/14-monitoring/{filepath}\")\n",
    "        if response.ok:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved {filepath}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch {filepath}\")\n",
    "\n",
    "fetch_file('data/synthetic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJxKxpI9sZ1M"
   },
   "source": [
    "## Metrics API: Data Extraction & Overview\n",
    "\n",
    "The Contextual AI Metrics API provides access to your RAG agent's conversation data, including:\n",
    "\n",
    "### Available Metrics\n",
    "\n",
    "- **Conversation Data**: Questions and  answers, timestamps\n",
    "- **User Feedback**: Thumbs up/down, flagged content, and custom feedback\n",
    "- **Retrieval Metrics**: Number of documents retrieved, relevance scores\n",
    "- **Usage Analytics**: User patterns, peak times, and engagement metrics\n",
    "\n",
    "### Query Parameters\n",
    "\n",
    "The Metrics API supports filtering options:\n",
    "\n",
    "- `agent_id`: Target specific RAG agents\n",
    "- `created_after/created_before`: Date range filtering\n",
    "- `conversation_id`: Filter by specific conversations\n",
    "- `user_id`: Analyze individual user interactions\n",
    "- `limit/offset`: Pagination for large datasets\n",
    "\n",
    "Let's start by extracting metrics data from an active Contextual AI RAG agent (if you don't have an active agent, just skip ahead to the next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Gi13r-BsZ1N"
   },
   "outputs": [],
   "source": [
    "# Specify your RAG agent ID\n",
    "# Replace with your actual agent ID\n",
    "agent_id = \"fd4ebb74-\"\n",
    "\n",
    "# Extract metrics data with date filtering\n",
    "# Adjust the date range based on your agent's activity\n",
    "metrics = client.agents.query.metrics(\n",
    "    agent_id=agent_id,\n",
    "    created_after=\"2025-07-30\"\n",
    ")\n",
    "\n",
    "print(f\"üìä Total conversations retrieved: {metrics.total_count}\")\n",
    "print(f\"üîó Agent ID: {agent_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZmY4A9CsZ1N"
   },
   "outputs": [],
   "source": [
    "# Convert metrics data to pandas DataFrame for analysis\n",
    "messages_list = metrics.messages\n",
    "\n",
    "# Create DataFrame from messages list\n",
    "df = pd.DataFrame(messages_list)\n",
    "\n",
    "print(f\"üìã DataFrame shape: {df.shape}\")\n",
    "print(f\"üìä Available columns: {list(df.columns)}\")\n",
    "print(\"\\nüîç First few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoAc6GgYsZ1N"
   },
   "source": [
    "## Demo Data: Synthetic Metrics for Analysis\n",
    "\n",
    "For demonstration purposes, we'll use synthetic metrics data that showcases RAG agent performance patterns.\n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "Our synthetic dataset includes:\n",
    "- **441 conversations** over a 9-day period\n",
    "- **Feedback data** (thumbs up/down, flagged content)\n",
    "- **Time-based usage variations** with peak hours and daily variations\n",
    "- **Quality metrics** including response length and content flags\n",
    "- **Delibrate errors included** to identify issues such as unavailable information\n",
    "\n",
    "Let's load and explore this demonstration data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spjuhXkHsZ1N"
   },
   "outputs": [],
   "source": [
    "# Load synthetic metrics data for demonstration\n",
    "df = pd.read_csv('data/synthetic_data.csv')\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "print(f\"üìä Dataset loaded successfully!\")\n",
    "print(f\"üìã Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"üìÖ Date range: {df['created_at'].min().strftime('%Y-%m-%d')} to {df['created_at'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"‚è∞ Total duration: {(df['created_at'].max() - df['created_at'].min()).days} days\")\n",
    "\n",
    "print(\"\\nüîç Sample data:\")\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylzNkMvSsZ1N"
   },
   "source": [
    "## Feature Engineering & Data Preparation\n",
    "\n",
    "To enable analytics, we'll create additional derived features that provide deeper insights into agent performance and user behavior.\n",
    "\n",
    "### Calculated Metrics\n",
    "\n",
    "We'll engineer features for:\n",
    "- **Content Analysis**: Word counts, response complexity\n",
    "- **Temporal Patterns**: Hourly/daily usage, peak activity times\n",
    "- **Quality Indicators**: Feedback patterns, flagged content detection\n",
    "- **Engagement Metrics**: User interaction patterns and satisfaction rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmiNQVfKsZ1N"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics and features\n",
    "print(\"üîß Engineering features for enhanced analysis...\")\n",
    "\n",
    "# Basic counts and statistics\n",
    "total_messages = len(df)\n",
    "feedback_counts = df['feedback'].value_counts().to_dict()\n",
    "feedback_counts['no_feedback'] = df['feedback'].isna().sum()\n",
    "flagged_count = df['issues'].apply(lambda x: x == '{}').sum()\n",
    "\n",
    "# Content analysis features\n",
    "df['question_word_count'] = df['question'].astype(str).apply(lambda x: len(x.split()))\n",
    "df['answer_word_count'] = df['answer'].astype(str).apply(lambda x: len(x.split()))\n",
    "df['no_relevant_docs_flag'] = df['answer'].str.contains(\"I don't have relevant documentation\", case=False, na=False)\n",
    "\n",
    "# Temporal features for time series analysis\n",
    "df['date'] = df['created_at'].dt.date\n",
    "df['hour'] = df['created_at'].dt.hour\n",
    "df['day_of_week'] = df['created_at'].dt.day_name()\n",
    "df['feedback_category'] = df['feedback'].fillna('no_feedback')\n",
    "df['has_feedback'] = df['feedback_category'] != 'no_feedback'\n",
    "\n",
    "print(\"‚úÖ Feature engineering complete!\")\n",
    "print(f\"üìä Total messages processed: {total_messages}\")\n",
    "print(f\"üìà New features added: {len(['question_word_count', 'answer_word_count', 'no_relevant_docs_flag', 'date', 'hour', 'day_of_week', 'feedback_category', 'has_feedback'])} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EndJW5V5sZ1O"
   },
   "source": [
    "## Feedback Analysis & Quality Metrics\n",
    "\n",
    "Understanding user feedback is crucial for monitoring RAG agent performance. This section provides insights into user satisfaction, quality issues, and areas for improvement.\n",
    "\n",
    "### Key Metrics Analyzed\n",
    "\n",
    "- **Feedback Distribution**: Overall satisfaction rates and feedback patterns\n",
    "- **Quality Indicators**: Flagged content and problematic responses\n",
    "- **Response Analysis**: Content length, complexity, and relevance flags\n",
    "- **Trend Analysis**: How feedback patterns change over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBuDQjWNsZ1O"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "print(\"üìä FEEDBACK ANALYSIS DASHBOARD\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìà Total Messages: {total_messages:,}\")\n",
    "print(f\"üìä Feedback Rate: {len(df[df['has_feedback']])/len(df)*100:.1f}%\")\n",
    "print(f\"üìÖ Analysis Period: {df['created_at'].min().strftime('%Y-%m-%d')} to {df['created_at'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(\"\\nüìã Feedback Distribution:\")\n",
    "for feedback, count in feedback_counts.items():\n",
    "    percentage = (count / total_messages) * 100\n",
    "    print(f\"   ‚Ä¢ {feedback.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüö© Quality Issues:\")\n",
    "print(f\"   ‚Ä¢ Flagged Messages: {flagged_count:,}\")\n",
    "print(f\"   ‚Ä¢ No Relevant Docs Responses: {df['no_relevant_docs_flag'].sum():,}\")\n",
    "\n",
    "# Create professional feedback distribution visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Main feedback distribution plot\n",
    "plt.subplot(2, 2, 1)\n",
    "colors = ['#2ca02c', '#d62728', '#ffd700', '#7f7f7f']  # Green, Red, Yellow, Gray\n",
    "feedback_series = pd.Series(feedback_counts)\n",
    "bars = plt.bar(feedback_series.index, feedback_series.values, color=colors, alpha=0.8)\n",
    "plt.title('Feedback Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feedback Type', fontsize=12)\n",
    "plt.ylabel('Number of Messages', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, feedback_series.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             f'{value:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Response length analysis\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(df['answer_word_count'], bins=30, alpha=0.7, color='#1f77b4', edgecolor='black')\n",
    "plt.title('Answer Length Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Word Count', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(df['answer_word_count'].mean(), color='red', linestyle='--',\n",
    "            label=f'Mean: {df[\"answer_word_count\"].mean():.1f}')\n",
    "plt.legend()\n",
    "\n",
    "# Question length analysis\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(df['question_word_count'], bins=20, alpha=0.7, color='#ff7f0e', edgecolor='black')\n",
    "plt.title('Question Length Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Word Count', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(df['question_word_count'].mean(), color='red', linestyle='--',\n",
    "            label=f'Mean: {df[\"question_word_count\"].mean():.1f}')\n",
    "plt.legend()\n",
    "\n",
    "# Daily activity pattern\n",
    "plt.subplot(2, 2, 4)\n",
    "daily_counts = df.groupby('day_of_week').size()\n",
    "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_counts = daily_counts.reindex(days_order, fill_value=0)\n",
    "plt.bar(daily_counts.index, daily_counts.values, color='#9467bd', alpha=0.8)\n",
    "plt.title('Daily Activity Pattern', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Number of Messages', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U2VDt2zsZ1O"
   },
   "source": [
    "## Time Series Analysis & Usage Patterns\n",
    "\n",
    "Understanding temporal patterns in RAG agent usage is essential for capacity planning, performance optimization, and user experience improvement. Here is an example interactive visualization for time-based analytics.\n",
    "\n",
    "### Analysis Features\n",
    "\n",
    "- **Hourly Usage Patterns**: Identify peak usage times and quiet periods\n",
    "- **Feedback Trends**: Track how user satisfaction changes over time\n",
    "- **Stacked Visualizations**: See feedback distribution within each time period\n",
    "- **Interactive Elements**: Hover for detailed information and zoom capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRivrbctsZ1O"
   },
   "outputs": [],
   "source": [
    "# Enhanced time series analysis with interactive visualizations\n",
    "print(\"üìä ENHANCED TIME SERIES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìà Total Messages: {len(df):,}\")\n",
    "print(f\"üìä Feedback Rate: {len(df[df['has_feedback']])/len(df)*100:.1f}%\")\n",
    "print(f\"üìÖ Date Range: {df['created_at'].min().strftime('%Y-%m-%d')} to {df['created_at'].max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Create interactive time series visualization\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Prepare hourly feedback data\n",
    "hourly_feedback_data = df.groupby([df['created_at'].dt.floor('h'), 'feedback_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure all feedback categories exist\n",
    "for category in ['no_feedback', 'thumbs_up', 'thumbs_down', 'flagged']:\n",
    "    if category not in hourly_feedback_data.columns:\n",
    "        hourly_feedback_data[category] = 0\n",
    "\n",
    "\n",
    "feedback_colors = {\n",
    "    'no_feedback': 'silver', #Gray\n",
    "    'thumbs_up': '#2ca02c',      # Green\n",
    "    'thumbs_down': '#d62728',    # Red\n",
    "    'flagged': '#ffd700'         # Yellow\n",
    "}\n",
    "\n",
    "for category, color in feedback_colors.items():\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=hourly_feedback_data.index,\n",
    "            y=hourly_feedback_data[category],\n",
    "            name=category.replace('_', ' ').title(),\n",
    "            marker_color=color,\n",
    "            opacity=1,\n",
    "            hovertemplate='<b>%{x}</b><br>' +\n",
    "                          f'{category.replace(\"_\", \" \").title()}: %{{y}}<br>' +\n",
    "                          '<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'üìä Messages Over Time - Stacked by Feedback Type',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20, 'color': '#2c3e50', 'family': 'Arial, sans-serif'}\n",
    "    },\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    barmode='stack',\n",
    "    plot_bgcolor='rgba(248, 249, 250, .6)',\n",
    "    paper_bgcolor='ghostwhite',\n",
    "    font=dict(family=\"Arial, sans-serif\", size=12, color=\"#2c3e50\"),\n",
    "    margin=dict(l=60, r=60, t=80, b=60),\n",
    "    hovermode='x unified',\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"ghostwhite\",\n",
    "        font_size=12,\n",
    "        font_family=\"Arial\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update axes with enhanced styling\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Time Period\",\n",
    "    title_font=dict(size=14, color=\"#2c3e50\"),\n",
    "    tickfont=dict(size=11),\n",
    "    gridcolor='rgba(128, 128, 128, 0.2)',\n",
    "    zeroline=False\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Messages per Hour\",\n",
    "    title_font=dict(size=14, color=\"#2c3e50\"),\n",
    "    tickfont=dict(size=11),\n",
    "    gridcolor='rgba(128, 128, 128, 0.2)',\n",
    "    zeroline=False\n",
    ")\n",
    "\n",
    "# Display the interactive dashboard\n",
    "fig.show()\n",
    "\n",
    "# Comprehensive analytics summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà KEY METRICS & INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "total_messages = len(df)\n",
    "feedback_messages = len(df[df['has_feedback']])\n",
    "feedback_rate = (feedback_messages / total_messages) * 100\n",
    "\n",
    "print(f\"üìä Total Messages: {total_messages:,}\")\n",
    "print(f\"üìà Feedback Rate: {feedback_rate:.1f}% ({feedback_messages:,}/{total_messages:,})\")\n",
    "\n",
    "if feedback_messages > 0:\n",
    "    positive_rate = (len(df[df['feedback_category'] == 'thumbs_up']) / feedback_messages) * 100\n",
    "    negative_rate = (len(df[df['feedback_category'] == 'thumbs_down']) / feedback_messages) * 100\n",
    "    flagged_rate = (len(df[df['feedback_category'] == 'flagged']) / feedback_messages) * 100\n",
    "\n",
    "    print(f\"üëç Positive Feedback: {positive_rate:.1f}%\")\n",
    "    print(f\"üëé Negative Feedback: {negative_rate:.1f}%\")\n",
    "    print(f\"üö© Flagged Content: {flagged_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚è∞ Temporal Analysis:\")\n",
    "print(f\"   ‚Ä¢ Peak Hour: {df.groupby('hour').size().idxmax()}:00\")\n",
    "print(f\"   ‚Ä¢ Most Active Day: {df.groupby('day_of_week').size().idxmax()}\")\n",
    "print(f\"   ‚Ä¢ Analysis Period: {(df['created_at'].max() - df['created_at'].min()).days} days\")\n",
    "\n",
    "print(f\"\\nüìù Content Analysis:\")\n",
    "print(f\"   ‚Ä¢ Avg Question Length: {df['question_word_count'].mean():.1f} words\")\n",
    "print(f\"   ‚Ä¢ Avg Answer Length: {df['answer_word_count'].mean():.1f} words\")\n",
    "print(f\"   ‚Ä¢ No Relevant Docs: {df['no_relevant_docs_flag'].sum():,} responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GgOHAZcsZ1O"
   },
   "source": [
    "## Advanced Analytics & Next Steps\n",
    "\n",
    "Using the Metrics Data you can calculate additional metrics:\n",
    "\n",
    "### 1. **Advanced Quality Assessment with External Libraries**\n",
    "- **RAGAS Integration**: Use libraries like RAGAS and LLM Judges to get metrics like:\n",
    "  - Response Relevancy\n",
    "  - Answer Correctness  \n",
    "  - Semantic Similarity\n",
    "  - Factual Correctness\n",
    "\n",
    "### 2. **Enhanced Monitoring with Retrieved Context**\n",
    "If you save or sample your queries, you can run more metrics including:\n",
    "- Additional RAGAS metrics (e.g., Faithfulness)\n",
    "- Groundedness Metric from Contextual AI\n",
    "- Number of retrievals for a query\n",
    "- Number of attributions for a query\n",
    "\n",
    "### Next Steps for Production Monitoring\n",
    "\n",
    "1. **Real-time Dashboards**: Set up automated data pipelines\n",
    "2. **Alerting Systems**: Monitor quality degradation in real-time  \n",
    "3. **A/B Testing**: Compare different RAG configurations\n",
    "4. **Custom Metrics**: Develop domain-specific quality indicators\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Contextual AI Documentation](https://docs.contextual.ai/user-guides/beginner-guide)\n",
    "- [RAGAS Evaluation](https://github.com/ContextualAI/examples/tree/main/07-evaluation-ragas)\n",
    "- [Retrieval Analysis](https://github.com/ContextualAI/examples/tree/main/11-retrieval-analysis)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
