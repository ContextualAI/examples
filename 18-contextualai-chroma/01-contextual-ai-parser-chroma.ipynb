{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/18-contextualai-chroma/01-contextual-ai-parser-chroma.ipynb)\n",
        "\n",
        "# Build Multi-Modal RAG with Chroma and Contextual AI Parser\n",
        "\n",
        "**Last updated:** October 2025\n",
        "\n",
        "**Versions used:**\n",
        "- Chroma version `latest`\n",
        "- Contextual AI client `latest`\n",
        "- OpenAI API (for embeddings and generation)\n",
        "\n",
        "This is a code recipe that uses [Chroma](https://docs.trychroma.com/) to perform multi-modal RAG over documents parsed by [Contextual AI Parser](https://docs.contextual.ai/api-reference/parse/parse-file).\n",
        "\n",
        "In this notebook, we accomplish the following:\n",
        "* Parse two distinct document types using Contextual AI Parser: research papers and table-rich documents\n",
        "* Extract structured markdown with document hierarchy preservation and advanced table extraction\n",
        "* Generate text embeddings with OpenAI\n",
        "* Perform multi-modal RAG using [Chroma](https://docs.trychroma.com/)\n",
        "\n",
        "To run this notebook, you'll need:\n",
        "* A [Contextual AI API key](https://docs.contextual.ai/user-guides/beginner-guide#get-your-api-key) - for document parsing and content extraction\n",
        "* An [OpenAI API key](https://platform.openai.com/docs/quickstart) - for text embeddings and generative responses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Contextual AI client and Chroma\n",
        "\n",
        "Note: If Colab prompts you to restart the session after running the cell below, click \"restart\" and proceed with running the rest of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --upgrade chromadb contextual-client openai requests rich\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "# Suppress Chroma client logs\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Part 1: Contextual AI Parser\n",
        "\n",
        "Contextual AI Parser is a cloud-based document parsing service that excels at extracting structured information from PDFs, DOC/DOCX, and PPT/PPTX files. It provides high-quality markdown extraction with document hierarchy preservation, making it ideal for RAG applications.\n",
        "\n",
        "The parser handles complex documents with images, tables, and hierarchical structures, providing multiple output formats including:\n",
        "- `markdown-document`: Single concatenated markdown output\n",
        "- `markdown-per-page`: Page-by-page markdown output\n",
        "- `blocks-per-page`: Structured JSON with document hierarchy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Documents to parse with Contextual AI\n",
        "documents = [\n",
        "    {\n",
        "        \"url\": \"https://arxiv.org/pdf/1706.03762\",\n",
        "        \"title\": \"Attention Is All You Need\",\n",
        "        \"type\": \"research_paper\",\n",
        "        \"description\": \"Seminal transformer architecture paper that introduced self-attention mechanisms\"\n",
        "    },\n",
        "    {\n",
        "        \"url\": \"https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/03-standalone-api/04-parse/data/omnidocbench-text.pdf\",\n",
        "        \"title\": \"OmniDocBench Dataset Documentation\", \n",
        "        \"type\": \"table_rich_document\",\n",
        "        \"description\": \"Dataset documentation with large tables demonstrating table extraction capabilities\"\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### API Keys Setup üîë\n",
        "\n",
        "We'll be using the Contextual AI API for parsing documents and OpenAI API for both generating text embeddings and for the generative model in our RAG pipeline. The code below dynamically fetches your API keys based on whether you're running this notebook in Google Colab or as a regular Jupyter notebook.\n",
        "\n",
        "If you're running this notebook in Google Colab, make sure you [add](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75) your API keys as secrets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API key variable names\n",
        "contextual_api_key_var = \"CONTEXTUAL_API_KEY\"  # Replace with the name of your secret/env var\n",
        "openai_api_key_var = \"OPENAI_API_KEY\"  # Replace with the name of your secret/env var\n",
        "\n",
        "# Fetch API keys\n",
        "try:\n",
        "    # If running in Colab, fetch API keys from Secrets\n",
        "    import google.colab\n",
        "    from google.colab import userdata\n",
        "    contextual_api_key = userdata.get(contextual_api_key_var)\n",
        "    openai_api_key = userdata.get(openai_api_key_var)\n",
        "    \n",
        "    if not contextual_api_key:\n",
        "        raise ValueError(f\"Secret '{contextual_api_key_var}' not found in Colab secrets.\")\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(f\"Secret '{openai_api_key_var}' not found in Colab secrets.\")\n",
        "except ImportError:\n",
        "    # If not running in Colab, fetch API keys from environment variables\n",
        "    import os\n",
        "    contextual_api_key = os.getenv(contextual_api_key_var)\n",
        "    openai_api_key = os.getenv(openai_api_key_var)\n",
        "    \n",
        "    if not contextual_api_key:\n",
        "        raise EnvironmentError(\n",
        "            f\"Environment variable '{contextual_api_key_var}' is not set. \"\n",
        "            \"Please define it before running this script.\"\n",
        "        )\n",
        "    if not openai_api_key:\n",
        "        raise EnvironmentError(\n",
        "            f\"Environment variable '{openai_api_key_var}' is not set. \"\n",
        "            \"Please define it before running this script.\"\n",
        "        )\n",
        "\n",
        "print(\"API keys configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and parse PDFs using Contextual AI Parser\n",
        "\n",
        "Here we use Contextual AI's Python SDK to parse a batch of PDFs. The result is structured markdown content with document hierarchy that we can use for text extraction and chunking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from contextual import ContextualAI\n",
        "from time import sleep\n",
        "import os\n",
        "\n",
        "# Setup Contextual AI client\n",
        "client = ContextualAI(api_key=contextual_api_key)\n",
        "\n",
        "# Create directory for downloaded PDFs\n",
        "os.makedirs(\"pdfs\", exist_ok=True)\n",
        "\n",
        "# Download PDFs and submit parse jobs\n",
        "job_data = []\n",
        "\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"Downloading and submitting parse job for: {doc['title']}\")\n",
        "    print(f\"Type: {doc['type']} - {doc['description']}\")\n",
        "    \n",
        "    # Download PDF\n",
        "    file_path = f\"pdfs/{doc['type']}_{i}.pdf\"\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(requests.get(doc['url']).content)\n",
        "    \n",
        "    # Configure parsing parameters based on document type\n",
        "    if doc['type'] == \"research_paper\":\n",
        "        # For research papers, focus on hierarchy and figures\n",
        "        parse_config = {\n",
        "            \"parse_mode\": \"standard\",\n",
        "            \"figure_caption_mode\": \"concise\",\n",
        "            \"enable_document_hierarchy\": True,\n",
        "            \"page_range\": \"0-5\"  # Parse first 6 pages\n",
        "        }\n",
        "    else:  # table_rich_document\n",
        "        # For table-rich documents, enable table splitting\n",
        "        parse_config = {\n",
        "            \"parse_mode\": \"standard\",\n",
        "            \"enable_split_tables\": True,\n",
        "            \"max_split_table_cells\": 100,\n",
        "        }\n",
        "    \n",
        "    # Submit parse job\n",
        "    with open(file_path, \"rb\") as fp:\n",
        "        response = client.parse.create(\n",
        "            raw_file=fp,\n",
        "            **parse_config\n",
        "        )\n",
        "    \n",
        "    job_data.append({\n",
        "        \"job_id\": response.job_id,\n",
        "        \"file_path\": file_path,\n",
        "        \"document\": doc\n",
        "    })\n",
        "    print(f\"Submitted job {response.job_id} for {doc['title']}\")\n",
        "\n",
        "print(f\"\\nSubmitted {len(job_data)} parse jobs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor parse job status and retrieve results\n",
        "\n",
        "We'll monitor all parse jobs and retrieve the results once they're completed. Contextual AI provides structured markdown with document hierarchy information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor all parse jobs\n",
        "completed_jobs = set()\n",
        "\n",
        "while len(completed_jobs) < len(job_data):\n",
        "    for i, job_info in enumerate(job_data):\n",
        "        job_id = job_info[\"job_id\"]\n",
        "        if job_id not in completed_jobs:\n",
        "            status = client.parse.job_status(job_id)\n",
        "            doc_title = job_info[\"document\"][\"title\"]\n",
        "            doc_type = job_info[\"document\"][\"type\"]\n",
        "            print(f\"Job {i+1}/{len(job_data)} ({doc_title} - {doc_type}): {status.status}\")\n",
        "            \n",
        "            if status.status == \"completed\":\n",
        "                completed_jobs.add(job_id)\n",
        "            elif status.status == \"failed\":\n",
        "                print(f\"Job failed for {doc_title}\")\n",
        "                completed_jobs.add(job_id)  # Add to completed to avoid infinite loop\n",
        "    \n",
        "    if len(completed_jobs) < len(job_data):\n",
        "        print(\"\\nWaiting for remaining jobs to complete...\")\n",
        "        sleep(30)\n",
        "\n",
        "print(\"\\nAll parse jobs completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíö Part 2: Chroma\n",
        "### Create and configure a Chroma collection\n",
        "\n",
        "[Chroma](https://docs.trychroma.com/) is an open-source embedding database that makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs. It provides efficient vector storage and similarity search capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Initialize Chroma client\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Use OpenAI embeddings\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=openai_api_key,\n",
        "    model_name=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "# Create collection\n",
        "collection_name = \"contextual_ai_rag_collection\"\n",
        "collection = chroma_client.create_collection(\n",
        "    name=collection_name,\n",
        "    embedding_function=openai_ef\n",
        ")\n",
        "\n",
        "print(f\"Created collection '{collection_name}' with OpenAI embeddings\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Retrieve and process parsed content\n",
        "\n",
        "We'll retrieve the parsed results and process them into chunks suitable for vector search. Contextual AI provides excellent document structure preservation, which we'll leverage for better RAG performance.\n",
        "\n",
        "**Key Feature**: Contextual AI preserves document hierarchy through `parent_ids`, allowing us to maintain section relationships and provide richer context to our RAG system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve results and process into chunks\n",
        "texts, titles, sources, doc_types = [], [], [], []\n",
        "\n",
        "for job_info in job_data:\n",
        "    job_id = job_info[\"job_id\"]\n",
        "    document = job_info[\"document\"]\n",
        "    \n",
        "    if job_id in completed_jobs:\n",
        "        try:\n",
        "            print(f\"Processing {document['title']} ({document['type']})\")\n",
        "            \n",
        "            # Get results with blocks-per-page for hierarchical information\n",
        "            results = client.parse.job_results(\n",
        "                job_id, \n",
        "                output_types=['blocks-per-page']\n",
        "            )\n",
        "            \n",
        "            print(f\"  - {len(results.pages)} pages parsed\")\n",
        "            \n",
        "            # Create hash table for parent content lookup\n",
        "            hash_table = {}\n",
        "            for page in results.pages:\n",
        "                for block in page.blocks:\n",
        "                    hash_table[block.id] = block.markdown\n",
        "            \n",
        "            # Process blocks with hierarchy context\n",
        "            for page in results.pages:\n",
        "                for block in page.blocks:\n",
        "                    # Filter blocks based on document type and content quality\n",
        "                    if (block.type in ['text', 'heading', 'table'] and \n",
        "                        len(block.markdown.strip()) > 30):\n",
        "                        \n",
        "                        # Add hierarchy context if available\n",
        "                        context_text = block.markdown\n",
        "                        \n",
        "                        if hasattr(block, 'parent_ids') and block.parent_ids:\n",
        "                            parent_content = \"\\n\".join([\n",
        "                                hash_table.get(parent_id, \"\") \n",
        "                                for parent_id in block.parent_ids\n",
        "                            ])\n",
        "                            if parent_content.strip():\n",
        "                                context_text = f\"{parent_content}\\n\\n{block.markdown}\"\n",
        "                        \n",
        "                        # Add document metadata as context\n",
        "                        full_text = f\"Document: {document['title']}\\nType: {document['type']}\\n\\n{context_text}\"\n",
        "                        \n",
        "                        texts.append(full_text)\n",
        "                        titles.append(document['title'])\n",
        "                        sources.append(f\"Page {page.index + 1}\")\n",
        "                        doc_types.append(document['type'])\n",
        "                        \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {document['title']}: {e}\")\n",
        "\n",
        "print(f\"\\nProcessed {len(texts)} chunks from {len(set(titles))} documents\")\n",
        "print(f\"Document types: {', '.join(set(doc_types))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wrangle data into an acceptable format for Chroma\n",
        "\n",
        "Transform our data from lists to a list of dictionaries for insertion into our Chroma collection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the data object\n",
        "data = []\n",
        "\n",
        "# Create a dictionary for each row by iterating through the corresponding lists\n",
        "for text, title, source, doc_type in zip(texts, titles, sources, doc_types):\n",
        "    data_point = {\n",
        "        \"text\": text,\n",
        "        \"title\": title,\n",
        "        \"source\": source,\n",
        "        \"document_type\": doc_type,\n",
        "    }\n",
        "    data.append(data_point)\n",
        "\n",
        "print(f\"Prepared {len(data)} chunks for insertion into Chroma\")\n",
        "print(f\"Chunks by document type:\")\n",
        "for doc_type in set(doc_types):\n",
        "    count = doc_types.count(doc_type)\n",
        "    print(f\"  - {doc_type}: {count} chunks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Insert data into Chroma and generate embeddings\n",
        "\n",
        "Embeddings will be generated upon insertion to our Chroma collection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert text chunks and metadata into Chroma collection\n",
        "collection.add(\n",
        "    documents=[item[\"text\"] for item in data],\n",
        "    metadatas=[{\n",
        "        \"title\": item[\"title\"],\n",
        "        \"source\": item[\"source\"],\n",
        "        \"document_type\": item[\"document_type\"]\n",
        "    } for item in data],\n",
        "    ids=[f\"chunk_{i}\" for i in range(len(data))]\n",
        ")\n",
        "\n",
        "print(\"Insert complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query the data\n",
        "\n",
        "Here, we perform a simple similarity search to return the most similar embedded chunks to our search query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Search for transformer-related content\n",
        "print(\"=== Searching for Transformer Architecture ===\")\n",
        "results = collection.query(\n",
        "    query_texts=[\"transformer architecture attention mechanism\"],\n",
        "    n_results=3,\n",
        "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
        ")\n",
        "\n",
        "for i, (doc, metadata, distance) in enumerate(zip(results['documents'][0], results['metadatas'][0], results['distances'][0])):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(f\"Title: {metadata['title']}\")\n",
        "    print(f\"Type: {metadata['document_type']}\")\n",
        "    print(f\"Source: {metadata['source']}\")\n",
        "    print(f\"Similarity: {1 - distance:.3f}\")\n",
        "    print(f\"Text preview: {doc[:200]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Example 2: Search for table-related content\n",
        "print(\"\\n=== Searching for Table/Data Content ===\")\n",
        "results = collection.query(\n",
        "    query_texts=[\"dataset table benchmark performance metrics\"],\n",
        "    n_results=3,\n",
        "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
        ")\n",
        "\n",
        "for i, (doc, metadata, distance) in enumerate(zip(results['documents'][0], results['metadatas'][0], results['distances'][0])):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(f\"Title: {metadata['title']}\")\n",
        "    print(f\"Type: {metadata['document_type']}\")\n",
        "    print(f\"Source: {metadata['source']}\")\n",
        "    print(f\"Similarity: {1 - distance:.3f}\")\n",
        "    print(f\"Text preview: {doc[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform RAG on parsed articles\n",
        "\n",
        "We'll use OpenAI's GPT model to generate responses based on the retrieved context from Chroma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Example 1: RAG on Transformer Architecture\n",
        "print(\"=== RAG Query: Transformer Architecture ===\")\n",
        "query = \"transformer attention mechanism\"\n",
        "prompt = f\"Explain how {query} works, using only the retrieved context.\"\n",
        "\n",
        "# Retrieve relevant documents\n",
        "results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=4,\n",
        "    include=[\"documents\", \"metadatas\"]\n",
        ")\n",
        "\n",
        "# Prepare context\n",
        "context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "# Generate response\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Use only the information from the context.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {prompt}\"}\n",
        "    ],\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "# Prettify the output using Rich\n",
        "console = Console()\n",
        "console.print(Panel(prompt, title=\"Prompt\", border_style=\"bold red\"))\n",
        "console.print(Panel(response.choices[0].message.content, title=\"Generated Content\", border_style=\"bold green\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: RAG on Dataset/Benchmark Information\n",
        "print(\"\\n=== RAG Query: Dataset and Benchmark Information ===\")\n",
        "query = \"dataset benchmark performance evaluation\"\n",
        "prompt = f\"What information does the retrieved context provide about {query}?\"\n",
        "\n",
        "# Retrieve relevant documents\n",
        "results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=4,\n",
        "    include=[\"documents\", \"metadatas\"]\n",
        ")\n",
        "\n",
        "# Prepare context\n",
        "context = \"\\n\\n\".join(results['documents'][0])\n",
        "\n",
        "# Generate response\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Use only the information from the context.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {prompt}\"}\n",
        "    ],\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "# Prettify the output using Rich\n",
        "console = Console()\n",
        "console.print(Panel(prompt, title=\"Prompt\", border_style=\"bold red\"))\n",
        "console.print(Panel(response.choices[0].message.content, title=\"Generated Content\", border_style=\"bold green\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a unique RAG pipeline using Contextual AI Parser and Chroma with two distinct document types:\n",
        "\n",
        "### What We Demonstrated:\n",
        "1. **Research Paper Parsing**: \"Attention is All You Need\" with document hierarchy preservation\n",
        "2. **Table-Rich Document Parsing**: OmniDocBench dataset with advanced table extraction\n",
        "3. **Multi-modal RAG**: Semantic search across different document types\n",
        "4. **Contextual Intelligence**: Leveraging document structure for better retrieval\n",
        "\n",
        "### Contextual AI Parser Advantages:\n",
        "- **Cloud-based processing**: No local GPU/compute requirements\n",
        "- **Document hierarchy preservation**: Maintains section relationships and structure\n",
        "- **Advanced table handling**: Smart table splitting with header propagation\n",
        "- **Multiple output formats**: Blocks, markdown, and structured JSON\n",
        "- **Production-ready**: Scalable cloud service with enterprise features\n",
        "\n",
        "### Key Differentiators from Other Parsers:\n",
        "- **Hierarchical context**: Parent-child relationships preserved in chunks\n",
        "- **Table intelligence**: Large tables automatically split with context preservation\n",
        "- **Document type awareness**: Different parsing strategies for different content types\n",
        "- **Rich metadata**: Document structure information enhances RAG quality\n",
        "\n",
        "### Chroma Integration Benefits:\n",
        "- **Multi-modal search**: Query across different document types simultaneously\n",
        "- **Metadata filtering**: Filter by document type, source, and other attributes\n",
        "- **Efficient storage**: Optimized vector database for embeddings\n",
        "- **Scalability**: From local development to cloud production\n",
        "\n",
        "### Next Steps for Enhancement:\n",
        "* Implement document-level metadata for better source attribution\n",
        "* Add hybrid search combining keyword and semantic search\n",
        "* Experiment with different chunking strategies for each document type\n",
        "* End-to-end RAG agents via [Contextual AI](https://docs.contextual.ai/user-guides/beginner-guide)\n",
        "* Get more information about integrating [Chroma](https://docs.trychroma.com/docs/overview/introduction)\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to get started?** This notebook provides a complete, production-ready example of integrating Contextual AI Parser with Chroma for sophisticated RAG applications. The combination of Contextual AI's advanced parsing capabilities and Chroma's powerful vector search features creates a robust foundation for document-based AI applications.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
