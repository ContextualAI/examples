{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BWP8eFqdMaN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextualAI/examples/blob/main/18-contextualai-chroma/02-contextual-ai-reranker-chroma.ipynb)\n",
        "\n",
        "# Using Contextual AI Reranker with Chroma\n",
        "\n",
        "**Last updated:** November 2025\n",
        "\n",
        "**Versions used:**\n",
        "- Chroma version `1.3.4`\n",
        "- Contextual AI client `0.9.0`\n",
        "\n",
        "Contextual AI's reranker is the first with instruction-following capabilities to handle conflicts in retrieval. It is on the performance/cost Pareto frontier for industry-leading benchmarks like BEIR. This notebook demonstrates how to integrate Contextual AI's reranker with Chroma for enhanced RAG pipelines.\n",
        "\n",
        "**Key Features:**\n",
        "- **Instruction-following reranking**: Handle complex retrieval scenarios with custom instructions\n",
        "- **BEIR performance/cost Pareto frontier**: Optimal balance of accuracy and efficiency\n",
        "- **Multi-lingual support**: Handle documents in multiple languages\n",
        "- **Chroma integration**: Seamless vector database integration for retrieval + reranking\n",
        "\n",
        "The current reranker models include:\n",
        "- ctxl-rerank-v2-instruct-multilingual\n",
        "- ctxl-rerank-v2-instruct-multilingual-mini\n",
        "- ctxl-rerank-v1-instruct\n",
        "\n",
        "**Open Source Version**: We also provide an open source version of our reranker available on [Hugging Face](https://huggingface.co/collections/ContextualAI/contextual-ai-reranker-v2) under the CC-BY-NC-SA-4.0 license.\n",
        "\n",
        "To run this notebook, you'll need:\n",
        "* A [Contextual AI API key](https://docs.contextual.ai/user-guides/beginner-guide) - for document parsing and content extraction.\n",
        "Visit [app.contextual.ai](https://app.contextual.ai/?utm_campaign=chroma&utm_source=contextualai&utm_medium=github&utm_content=notebook) and click the **\"Start Free\"** button to sign up and receive free credits\n",
        "* An [OpenAI API key](https://platform.openai.com/docs/quickstart) - for text embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3RRGBs1dMaP"
      },
      "source": [
        "## Installation and Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3pVig3B9dMaP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --upgrade chromadb contextual-client openai requests rich\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "# Suppress Chroma client logs\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp_IjEROdMaQ"
      },
      "source": [
        "### API Keys Setup ğŸ”‘\n",
        "\n",
        "We'll be using the Contextual AI API for reranking and OpenAI API for embeddings. The code below dynamically fetches your API keys based on whether you're running this notebook in Google Colab or as a regular Jupyter notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYKGmXzOdMaQ",
        "outputId": "01faae32-f649-4991-e82b-b80ff4094a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API keys configured successfully!\n"
          ]
        }
      ],
      "source": [
        "# API key variable names\n",
        "contextual_api_key_var = \"CONTEXTUAL_API_KEY\"  # Replace with the name of your secret/env var\n",
        "openai_api_key_var = \"OPENAI_API_KEY\"  # Replace with the name of your secret/env var\n",
        "\n",
        "# Fetch API keys\n",
        "try:\n",
        "    # If running in Colab, fetch API keys from Secrets\n",
        "    import google.colab\n",
        "    from google.colab import userdata\n",
        "    contextual_api_key = userdata.get(contextual_api_key_var)\n",
        "    openai_api_key = userdata.get(openai_api_key_var)\n",
        "\n",
        "    if not contextual_api_key:\n",
        "        raise ValueError(f\"Secret '{contextual_api_key_var}' not found in Colab secrets.\")\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(f\"Secret '{openai_api_key_var}' not found in Colab secrets.\")\n",
        "except ImportError:\n",
        "    # If not running in Colab, fetch API keys from environment variables\n",
        "    import os\n",
        "    contextual_api_key = os.getenv(contextual_api_key_var)\n",
        "    openai_api_key = os.getenv(openai_api_key_var)\n",
        "\n",
        "    if not contextual_api_key:\n",
        "        raise EnvironmentError(\n",
        "            f\"Environment variable '{contextual_api_key_var}' is not set. \"\n",
        "            \"Please define it before running this script.\"\n",
        "        )\n",
        "    if not openai_api_key:\n",
        "        raise EnvironmentError(\n",
        "            f\"Environment variable '{openai_api_key_var}' is not set. \"\n",
        "            \"Please define it before running this script.\"\n",
        "        )\n",
        "\n",
        "print(\"API keys configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx6KrCoIdMaQ"
      },
      "source": [
        "## Part 1: Setup Chroma with Sample Data\n",
        "\n",
        "Let's create a Chroma collection with sample enterprise documents to demonstrate the reranking capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRD9CyccdMaQ",
        "outputId": "e7007ca6-6ae7-4af7-e579-0ae29c8aaf03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection 'enterprise_documents' with OpenAI embeddings\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from contextual import ContextualAI\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "\n",
        "# Initialize clients\n",
        "contextual_client = ContextualAI(api_key=contextual_api_key)\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Use OpenAI embeddings\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=openai_api_key,\n",
        "    model_name=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "# Create collection\n",
        "collection_name = \"enterprise_documents\"\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=collection_name,\n",
        "    embedding_function=openai_ef\n",
        ")\n",
        "\n",
        "print(f\"Created collection '{collection_name}' with OpenAI embeddings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz49xdZDdMaQ",
        "outputId": "dbd7e7f1-bb3f-4e8c-f29e-e3d4a645df40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 6 documents to Chroma collection\n"
          ]
        }
      ],
      "source": [
        "# Sample enterprise documents with different types and dates\n",
        "sample_documents = [\n",
        "    {\n",
        "        \"content\": \"Following detailed cost analysis and market research, we have implemented the following changes: AI training clusters will see a 15% uplift in raw compute performance, enterprise support packages are being restructured, and bulk procurement programs (100+ units) for the RTX 5090 Enterprise series will operate on a $2,899 baseline.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Enterprise GPU Pricing Update\",\n",
        "            \"date\": \"2025-01-15\",\n",
        "            \"source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "            \"classification\": \"Internal Use Only\",\n",
        "            \"department\": \"Sales\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 per unit. This pricing for RTX 5090 enterprise bulk orders has been confirmed across all major distribution channels.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Market Analysis Report\",\n",
        "            \"date\": \"2023-11-30\",\n",
        "            \"source\": \"TechAnalytics Research Group\",\n",
        "            \"classification\": \"Public\",\n",
        "            \"department\": \"Research\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead. Power consumption analysis shows optimal performance at 85% utilization with enterprise-grade cooling solutions.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Technical Specifications\",\n",
        "            \"date\": \"2025-01-25\",\n",
        "            \"source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "            \"classification\": \"Internal Use Only\",\n",
        "            \"department\": \"Engineering\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Our enterprise customers have reported significant performance improvements with the RTX 5090 in AI workloads. Training times reduced by 40% compared to previous generation GPUs.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Customer Performance Report\",\n",
        "            \"date\": \"2025-01-10\",\n",
        "            \"source\": \"Customer Success Team\",\n",
        "            \"classification\": \"Confidential\",\n",
        "            \"department\": \"Customer Success\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"The RTX 5090 represents a breakthrough in enterprise AI computing. With 128GB of HBM3e memory and 2.5x faster training performance, it's designed for the most demanding AI workloads.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Product Launch Announcement\",\n",
        "            \"date\": \"2024-12-01\",\n",
        "            \"source\": \"Marketing Department\",\n",
        "            \"classification\": \"Public\",\n",
        "            \"department\": \"Marketing\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Internal memo: RTX 5090 enterprise pricing strategy has been revised. New baseline pricing effective January 15, 2025: $2,899 for bulk orders (100+ units), $3,200 for standard enterprise orders.\",\n",
        "        \"metadata\": {\n",
        "            \"title\": \"Internal Pricing Memo\",\n",
        "            \"date\": \"2025-01-12\",\n",
        "            \"source\": \"Executive Team\",\n",
        "            \"classification\": \"Internal Use Only\",\n",
        "            \"department\": \"Executive\"\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Add documents to Chroma\n",
        "documents = [doc[\"content\"] for doc in sample_documents]\n",
        "metadatas = [doc[\"metadata\"] for doc in sample_documents]\n",
        "ids = [f\"doc_{i}\" for i in range(len(sample_documents))]\n",
        "\n",
        "collection.add(\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(f\"Added {len(sample_documents)} documents to Chroma collection\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-TayaOpdMaR"
      },
      "source": [
        "## Part 2: Basic Retrieval vs. Reranked Retrieval\n",
        "\n",
        "Let's demonstrate the difference between basic Chroma retrieval and Contextual AI's instruction-following reranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lzwHAIhdMaR",
        "outputId": "3dcedcb5-d521-4d60-b257-c2bf9fc143aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\n",
            "Instruction: Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Query and instruction for reranking\n",
        "query = \"What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\"\n",
        "\n",
        "instruction = \"Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\"\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Instruction: {instruction}\")\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20SqwAsydMaR",
        "outputId": "1c7cdec9-4a87-4f1a-9ffc-d8b4ff5f4140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” BASIC CHROMA RETRIEVAL\n",
            "==================================================\n",
            "Retrieved 6 documents from Chroma\n",
            "\n",
            "Chroma Results (ordered by similarity):\n",
            "\n",
            "1. Market Analysis Report (Similarity: 0.816)\n",
            "   Source: TechAnalytics Research Group | Date: 2023-11-30\n",
            "   Classification: Public\n",
            "   Content: Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 p...\n",
            "\n",
            "2. Internal Pricing Memo (Similarity: 0.638)\n",
            "   Source: Executive Team | Date: 2025-01-12\n",
            "   Classification: Internal Use Only\n",
            "   Content: Internal memo: RTX 5090 enterprise pricing strategy has been revised. New baseline pricing effective...\n",
            "\n",
            "3. Enterprise GPU Pricing Update (Similarity: 0.292)\n",
            "   Source: NVIDIA Enterprise Sales Portal | Date: 2025-01-15\n",
            "   Classification: Internal Use Only\n",
            "   Content: Following detailed cost analysis and market research, we have implemented the following changes: AI ...\n",
            "\n",
            "4. Customer Performance Report (Similarity: 0.218)\n",
            "   Source: Customer Success Team | Date: 2025-01-10\n",
            "   Classification: Confidential\n",
            "   Content: Our enterprise customers have reported significant performance improvements with the RTX 5090 in AI ...\n",
            "\n",
            "5. Product Launch Announcement (Similarity: 0.174)\n",
            "   Source: Marketing Department | Date: 2024-12-01\n",
            "   Classification: Public\n",
            "   Content: The RTX 5090 represents a breakthrough in enterprise AI computing. With 128GB of HBM3e memory and 2....\n",
            "\n",
            "6. Technical Specifications (Similarity: 0.160)\n",
            "   Source: NVIDIA Enterprise Sales Portal | Date: 2025-01-25\n",
            "   Classification: Internal Use Only\n",
            "   Content: RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead. Power consumption analysis shows...\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Basic Chroma retrieval\n",
        "print(\"ğŸ” BASIC CHROMA RETRIEVAL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Retrieve more documents than we need for reranking\n",
        "chroma_results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=6,  # Get all documents for reranking\n",
        "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
        ")\n",
        "\n",
        "print(f\"Retrieved {len(chroma_results['documents'][0])} documents from Chroma\")\n",
        "print(\"\\nChroma Results (ordered by similarity):\")\n",
        "for i, (doc, metadata, distance) in enumerate(zip(\n",
        "    chroma_results['documents'][0],\n",
        "    chroma_results['metadatas'][0],\n",
        "    chroma_results['distances'][0]\n",
        ")):\n",
        "    print(f\"\\n{i+1}. {metadata['title']} (Similarity: {1-distance:.3f})\")\n",
        "    print(f\"   Source: {metadata['source']} | Date: {metadata['date']}\")\n",
        "    print(f\"   Classification: {metadata['classification']}\")\n",
        "    print(f\"   Content: {doc[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTzOVs9DdMaR",
        "outputId": "d35b1f0e-5531-48f7-e3e7-b5d411da11a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ğŸ¯ CONTEXTUAL AI RERANKING\n",
            "==================================================\n",
            "Reranked 6 documents using instruction-following reranking\n",
            "\n",
            "Reranked Results (ordered by relevance + instruction):\n",
            "\n",
            "1. Enterprise GPU Pricing Update (Score: 1.000)\n",
            "   Source: NVIDIA Enterprise Sales Portal | Date: 2025-01-15\n",
            "   Classification: Internal Use Only\n",
            "   Content: Following detailed cost analysis and market research, we have implemented the following changes: AI ...\n",
            "\n",
            "2. Internal Pricing Memo (Score: 1.000)\n",
            "   Source: Executive Team | Date: 2025-01-12\n",
            "   Classification: Internal Use Only\n",
            "   Content: Internal memo: RTX 5090 enterprise pricing strategy has been revised. New baseline pricing effective...\n",
            "\n",
            "3. Market Analysis Report (Score: 0.987)\n",
            "   Source: TechAnalytics Research Group | Date: 2023-11-30\n",
            "   Classification: Public\n",
            "   Content: Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 p...\n",
            "\n",
            "4. Technical Specifications (Score: 0.923)\n",
            "   Source: NVIDIA Enterprise Sales Portal | Date: 2025-01-25\n",
            "   Classification: Internal Use Only\n",
            "   Content: RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead. Power consumption analysis shows...\n",
            "\n",
            "5. Customer Performance Report (Score: 0.531)\n",
            "   Source: Customer Success Team | Date: 2025-01-10\n",
            "   Classification: Confidential\n",
            "   Content: Our enterprise customers have reported significant performance improvements with the RTX 5090 in AI ...\n",
            "\n",
            "6. Product Launch Announcement (Score: 0.329)\n",
            "   Source: Marketing Department | Date: 2024-12-01\n",
            "   Classification: Public\n",
            "   Content: The RTX 5090 represents a breakthrough in enterprise AI computing. With 128GB of HBM3e memory and 2....\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Contextual AI Reranking\n",
        "print(\"\\n\\nğŸ¯ CONTEXTUAL AI RERANKING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Prepare documents and metadata for reranking\n",
        "documents_to_rerank = chroma_results['documents'][0]\n",
        "metadata_for_rerank = [str(meta) for meta in chroma_results['metadatas'][0]]\n",
        "\n",
        "# Apply Contextual AI reranking with instruction\n",
        "rerank_response = contextual_client.rerank.create(\n",
        "    query=query,\n",
        "    instruction=instruction,\n",
        "    documents=documents_to_rerank,\n",
        "    metadata=metadata_for_rerank,\n",
        "    model=\"ctxl-rerank-v2-instruct-multilingual\"\n",
        ")\n",
        "\n",
        "print(f\"Reranked {len(rerank_response.results)} documents using instruction-following reranking\")\n",
        "print(\"\\nReranked Results (ordered by relevance + instruction):\")\n",
        "for i, result in enumerate(rerank_response.results):\n",
        "    original_index = result.index\n",
        "    original_metadata = chroma_results['metadatas'][0][original_index]\n",
        "    original_doc = chroma_results['documents'][0][original_index]\n",
        "\n",
        "    print(f\"\\n{i+1}. {original_metadata['title']} (Score: {result.relevance_score:.3f})\")\n",
        "    print(f\"   Source: {original_metadata['source']} | Date: {original_metadata['date']}\")\n",
        "    print(f\"   Classification: {original_metadata['classification']}\")\n",
        "    print(f\"   Content: {original_doc[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVy1wJdydMaR"
      },
      "source": [
        "## Part 3: Complete RAG Pipeline with Reranking\n",
        "\n",
        "Now let's demonstrate a complete RAG pipeline that combines Chroma retrieval, Contextual AI reranking, and LLM generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "SmlP_T4KdMaR",
        "outputId": "02cfed8b-954e-4aae-afb3-82affa306ec3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mğŸš€ COMPLETE RAG PIPELINE DEMO\u001b[0m\u001b[1;35m                                                                                  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ ğŸš€ COMPLETE RAG PIPELINE DEMO                                                                                   â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;34mâ”‚\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mStep 1: Retrieving from Chroma\u001b[0m\u001b[1;34m                                                                                 \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mâ”‚\u001b[0m\n",
              "\u001b[1;34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚ Step 1: Retrieving from Chroma                                                                                  â”‚</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mStep 2: Reranking with Contextual AI\u001b[0m\u001b[1;32m                                                                           \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚ Step 2: Reranking with Contextual AI                                                                            â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;33mâ”‚\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mStep 3: Generating response with LLM\u001b[0m\u001b[1;33m                                                                           \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mâ”‚\u001b[0m\n",
              "\u001b[1;33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â”‚ Step 3: Generating response with LLM                                                                            â”‚</span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mâ•­â”€\u001b[0m\u001b[1;32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;32m Generated Response \u001b[0m\u001b[1;32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;32mâ”€â•®\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m The memo contains conflicting figures. As of now, enterprise bulk pricing is reported as $3,100â€“$3,300 per unit \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m (confirmed across major distribution channels) (Context: \"Enterprise pricing for the RTX 5090 GPU bulk orders   \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m (100+ units) is currently set at $3,100-$3,300 per unit. This pricing ... has been confirmed across all major   \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m distribution channels.\"). However, a revised baseline of $2,899 for bulk orders (100+ units) is scheduled       \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m effective January 15, 2025 (Context: \"New baseline pricing effective January 15, 2025: $2,899 for bulk orders   \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m (100+ units)\" and \"bulk procurement programs (100+ units) ... will operate on a $2,899 baseline.\").             \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Generated Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> The memo contains conflicting figures. As of now, enterprise bulk pricing is reported as $3,100â€“$3,300 per unit <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> (confirmed across major distribution channels) (Context: \"Enterprise pricing for the RTX 5090 GPU bulk orders   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> (100+ units) is currently set at $3,100-$3,300 per unit. This pricing ... has been confirmed across all major   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> distribution channels.\"). However, a revised baseline of $2,899 for bulk orders (100+ units) is scheduled       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> effective January 15, 2025 (Context: \"New baseline pricing effective January 15, 2025: $2,899 for bulk orders   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> (100+ units)\" and \"bulk procurement programs (100+ units) ... will operate on a $2,899 baseline.\").             <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34mâ•­â”€\u001b[0m\u001b[1;34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;34m Sources \u001b[0m\u001b[1;34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;34mâ”€â•®\u001b[0m\n",
              "\u001b[1;34mâ”‚\u001b[0m Sources used: ['Internal Pricing Memo', 'Enterprise GPU Pricing Update', 'Market Analysis Report']              \u001b[1;34mâ”‚\u001b[0m\n",
              "\u001b[1;34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚</span> Sources used: ['Internal Pricing Memo', 'Enterprise GPU Pricing Update', 'Market Analysis Report']              <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "def complete_rag_pipeline(query, instruction, top_k=3):\n",
        "    \"\"\"\n",
        "    Complete RAG pipeline: Chroma retrieval + Contextual AI reranking + LLM generation\n",
        "    \"\"\"\n",
        "    console = Console()\n",
        "\n",
        "    # Step 1: Retrieve from Chroma\n",
        "    console.print(Panel(\"Step 1: Retrieving from Chroma\", style=\"bold blue\"))\n",
        "    chroma_results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=6,  # Get more for reranking\n",
        "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "    )\n",
        "\n",
        "    # Step 2: Rerank with Contextual AI\n",
        "    console.print(Panel(\"Step 2: Reranking with Contextual AI\", style=\"bold green\"))\n",
        "    documents_to_rerank = chroma_results['documents'][0]\n",
        "    metadata_for_rerank = [str(meta) for meta in chroma_results['metadatas'][0]]\n",
        "\n",
        "    rerank_response = contextual_client.rerank.create(\n",
        "        query=query,\n",
        "        instruction=instruction,\n",
        "        documents=documents_to_rerank,\n",
        "        metadata=metadata_for_rerank,\n",
        "        model=\"ctxl-rerank-v2-instruct-multilingual\"\n",
        "    )\n",
        "\n",
        "    # Step 3: Get top-k reranked documents\n",
        "    top_docs = []\n",
        "    top_metadata = []\n",
        "\n",
        "    for i in range(min(top_k, len(rerank_response.results))):\n",
        "        result = rerank_response.results[i]\n",
        "        original_index = result.index\n",
        "        top_docs.append(chroma_results['documents'][0][original_index])\n",
        "        top_metadata.append(chroma_results['metadatas'][0][original_index])\n",
        "\n",
        "    # Step 4: Generate response with LLM\n",
        "    console.print(Panel(\"Step 3: Generating response with LLM\", style=\"bold yellow\"))\n",
        "    context = \"\\n\\n\".join(top_docs)\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-5-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Use only the information from the context and cite your sources.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n",
        "        ],\n",
        "        temperature=1\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"response\": response.choices[0].message.content,\n",
        "        \"sources\": top_metadata,\n",
        "        \"rerank_scores\": [result.relevance_score for result in rerank_response.results[:top_k]]\n",
        "    }\n",
        "\n",
        "# Example 1: Enterprise pricing query\n",
        "console = Console()\n",
        "console.print(Panel(\"ğŸš€ COMPLETE RAG PIPELINE DEMO\", style=\"bold magenta\"))\n",
        "\n",
        "result = complete_rag_pipeline(\n",
        "    query=\"What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\",\n",
        "    instruction=\"Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\",\n",
        "    top_k=3\n",
        ")\n",
        "\n",
        "console.print(Panel(result[\"response\"], title=\"Generated Response\", border_style=\"bold green\"))\n",
        "console.print(Panel(f\"Sources used: {[meta['title'] for meta in result['sources']]}\", title=\"Sources\", border_style=\"bold blue\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "JVGKB2h4dMaS",
        "outputId": "88012edf-7d88-4a08-af6c-5cc8767fde08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;36mâ”‚\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mğŸ”§ TECHNICAL SPECIFICATIONS QUERY\u001b[0m\u001b[1;36m                                                                              \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mâ”‚\u001b[0m\n",
              "\u001b[1;36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">â”‚ ğŸ”§ TECHNICAL SPECIFICATIONS QUERY                                                                               â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;34mâ”‚\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mStep 1: Retrieving from Chroma\u001b[0m\u001b[1;34m                                                                                 \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34mâ”‚\u001b[0m\n",
              "\u001b[1;34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚ Step 1: Retrieving from Chroma                                                                                  â”‚</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mStep 2: Reranking with Contextual AI\u001b[0m\u001b[1;32m                                                                           \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚ Step 2: Reranking with Contextual AI                                                                            â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;33mâ”‚\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mStep 3: Generating response with LLM\u001b[0m\u001b[1;33m                                                                           \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mâ”‚\u001b[0m\n",
              "\u001b[1;33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â”‚ Step 3: Generating response with LLM                                                                            â”‚</span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mâ•­â”€\u001b[0m\u001b[1;32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;32m Generated Response \u001b[0m\u001b[1;32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;32mâ”€â•®\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m Summary (from provided context)                                                                                 \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m                                                                                                                 \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m - Model: RTX 5090 Enterprise GPU. (Context)                                                                     \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m - Thermal Design Power (TDP): 450 W. (Context: \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling       \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m overhead.\")                                                                                                     \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m - Cooling overhead required: 20% above TDP â€” plan cooling for 450 W Ã— 1.20 = 540 W of heat removal capacity.    \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m (Context: \"20% cooling overhead.\")                                                                              \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m - Recommended operating point: power-consumption analysis shows optimal performance at about 85% utilization    \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m when paired with enterpriseâ€‘grade cooling solutions. (Context: \"Power consumption analysis shows optimal        \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m performance at 85% utilization with enterprise-grade cooling solutions.\")                                       \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m - Approximate operating power at that point: ~85% of 450 W â‰ˆ 382.5 W (derived from the TDP and the stated       \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m optimal utilization). (Context: TDP = 450 W; \"85% utilization\")                                                 \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m                                                                                                                 \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m Notes: enterprise customers reported significant AI performance gains (training times reduced ~40%), which      \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m supports deploying appropriate cooling and power provisioning for best results. (Context: \"Training times       \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ”‚\u001b[0m reduced by 40% compared to previous generation GPUs.\")                                                          \u001b[1;32mâ”‚\u001b[0m\n",
              "\u001b[1;32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Generated Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> Summary (from provided context)                                                                                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> - Model: RTX 5090 Enterprise GPU. (Context)                                                                     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> - Thermal Design Power (TDP): 450 W. (Context: \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> overhead.\")                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> - Cooling overhead required: 20% above TDP â€” plan cooling for 450 W Ã— 1.20 = 540 W of heat removal capacity.    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> (Context: \"20% cooling overhead.\")                                                                              <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> - Recommended operating point: power-consumption analysis shows optimal performance at about 85% utilization    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> when paired with enterpriseâ€‘grade cooling solutions. (Context: \"Power consumption analysis shows optimal        <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> performance at 85% utilization with enterprise-grade cooling solutions.\")                                       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> - Approximate operating power at that point: ~85% of 450 W â‰ˆ 382.5 W (derived from the TDP and the stated       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> optimal utilization). (Context: TDP = 450 W; \"85% utilization\")                                                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> Notes: enterprise customers reported significant AI performance gains (training times reduced ~40%), which      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> supports deploying appropriate cooling and power provisioning for best results. (Context: \"Training times       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span> reduced by 40% compared to previous generation GPUs.\")                                                          <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34mâ•­â”€\u001b[0m\u001b[1;34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;34m Sources \u001b[0m\u001b[1;34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[1;34mâ”€â•®\u001b[0m\n",
              "\u001b[1;34mâ”‚\u001b[0m Sources used: ['Technical Specifications', 'Customer Performance Report', 'Internal Pricing Memo']              \u001b[1;34mâ”‚\u001b[0m\n",
              "\u001b[1;34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚</span> Sources used: ['Technical Specifications', 'Customer Performance Report', 'Internal Pricing Memo']              <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â”‚</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example 2: Technical specifications query with different instruction\n",
        "console.print(Panel(\"ğŸ”§ TECHNICAL SPECIFICATIONS QUERY\", style=\"bold cyan\"))\n",
        "\n",
        "result2 = complete_rag_pipeline(\n",
        "    query=\"What are the technical specifications and power requirements for the RTX 5090?\",\n",
        "    instruction=\"Prioritize technical documentation and engineering specifications. Internal technical documents should rank higher than marketing materials. Focus on detailed specifications and performance metrics.\",\n",
        "    top_k=3\n",
        ")\n",
        "\n",
        "console.print(Panel(result2[\"response\"], title=\"Generated Response\", border_style=\"bold green\"))\n",
        "console.print(Panel(f\"Sources used: {[meta['title'] for meta in result2['sources']]}\", title=\"Sources\", border_style=\"bold blue\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYvcGNh8dMaS"
      },
      "source": [
        "## Part 4: Advanced Reranking Scenarios\n",
        "\n",
        "Let's demonstrate different reranking scenarios to show the flexibility of instruction-following reranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "E198TPkYdMaS",
        "outputId": "405bda52-2784-4372-d147-bee4e0038e6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mğŸ”„ COMPARING RERANKING STRATEGIES\u001b[0m\u001b[1;35m                                                                              \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ ğŸ”„ COMPARING RERANKING STRATEGIES                                                                               â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Query: What is the current status and pricing for RTX \u001b[1;36m5090\u001b[0m enterprise GPUs?\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Query: What is the current status and pricing for RTX <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5090</span> enterprise GPUs?\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mStrategy: Recent Documents First\u001b[0m\u001b[1;35m                                                                               \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ Strategy: Recent Documents First                                                                                â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Instruction: Prioritize the most recent documents. Documents from \u001b[1;36m2025\u001b[0m should rank higher than older documents.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Instruction: Prioritize the most recent documents. Documents from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span> should rank higher than older documents.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Top \u001b[1;36m3\u001b[0m Results:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> Results:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m1\u001b[0m. Internal Pricing Memo \u001b[1m(\u001b[0mScore: \u001b[1;36m1.000\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Internal Pricing Memo <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m2\u001b[0m. Enterprise GPU Pricing Update \u001b[1m(\u001b[0mScore: \u001b[1;36m1.000\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Enterprise GPU Pricing Update <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m3\u001b[0m. Market Analysis Report \u001b[1m(\u001b[0mScore: \u001b[1;36m1.000\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Market Analysis Report <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "============================================================\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "============================================================\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mStrategy: Internal Documents Priority\u001b[0m\u001b[1;35m                                                                          \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ Strategy: Internal Documents Priority                                                                           â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Instruction: Prioritize internal and confidential documents over public documents. Internal Use Only and \n",
              "Confidential documents should rank highest.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Instruction: Prioritize internal and confidential documents over public documents. Internal Use Only and \n",
              "Confidential documents should rank highest.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Top \u001b[1;36m3\u001b[0m Results:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> Results:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m1\u001b[0m. Internal Pricing Memo \u001b[1m(\u001b[0mScore: \u001b[1;36m1.000\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Internal Pricing Memo <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m2\u001b[0m. Enterprise GPU Pricing Update \u001b[1m(\u001b[0mScore: \u001b[1;36m0.996\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Enterprise GPU Pricing Update <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.996</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m3\u001b[0m. Customer Performance Report \u001b[1m(\u001b[0mScore: \u001b[1;36m0.974\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Customer Performance Report <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.974</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "============================================================\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "============================================================\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mStrategy: Department-Specific\u001b[0m\u001b[1;35m                                                                                  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ Strategy: Department-Specific                                                                                   â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Instruction: Prioritize documents from Sales and Engineering departments. Customer Success and Marketing documents \n",
              "should rank lower.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Instruction: Prioritize documents from Sales and Engineering departments. Customer Success and Marketing documents \n",
              "should rank lower.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Top \u001b[1;36m3\u001b[0m Results:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> Results:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m1\u001b[0m. Market Analysis Report \u001b[1m(\u001b[0mScore: \u001b[1;36m0.993\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Market Analysis Report <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.993</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m2\u001b[0m. Enterprise GPU Pricing Update \u001b[1m(\u001b[0mScore: \u001b[1;36m0.985\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Enterprise GPU Pricing Update <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.985</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m3\u001b[0m. Technical Specifications \u001b[1m(\u001b[0mScore: \u001b[1;36m0.924\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Technical Specifications <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.924</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "============================================================\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "============================================================\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
              "\u001b[1;35mâ”‚\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mStrategy: Source Authority\u001b[0m\u001b[1;35m                                                                                     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mâ”‚\u001b[0m\n",
              "\u001b[1;35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â”‚ Strategy: Source Authority                                                                                      â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Instruction: Prioritize documents from NVIDIA Enterprise Sales Portal and Executive Team. External sources like \n",
              "TechAnalytics should rank lower.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Instruction: Prioritize documents from NVIDIA Enterprise Sales Portal and Executive Team. External sources like \n",
              "TechAnalytics should rank lower.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Top \u001b[1;36m3\u001b[0m Results:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> Results:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m1\u001b[0m. Enterprise GPU Pricing Update \u001b[1m(\u001b[0mScore: \u001b[1;36m0.990\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Enterprise GPU Pricing Update <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.990</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m2\u001b[0m. Internal Pricing Memo \u001b[1m(\u001b[0mScore: \u001b[1;36m0.982\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Internal Pricing Memo <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.982</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  \u001b[1;36m3\u001b[0m. Market Analysis Report \u001b[1m(\u001b[0mScore: \u001b[1;36m0.944\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Market Analysis Report <span style=\"font-weight: bold\">(</span>Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.944</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "============================================================\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "============================================================\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def compare_reranking_strategies(query, strategies):\n",
        "    \"\"\"\n",
        "    Compare different reranking strategies for the same query\n",
        "    \"\"\"\n",
        "    console = Console()\n",
        "\n",
        "    # Get initial results from Chroma\n",
        "    chroma_results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=6,\n",
        "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "    )\n",
        "\n",
        "    documents_to_rerank = chroma_results['documents'][0]\n",
        "    metadata_for_rerank = [str(meta) for meta in chroma_results['metadatas'][0]]\n",
        "\n",
        "    for strategy_name, instruction in strategies.items():\n",
        "        console.print(Panel(f\"Strategy: {strategy_name}\", style=\"bold magenta\"))\n",
        "        console.print(f\"Instruction: {instruction}\")\n",
        "\n",
        "        # Apply reranking\n",
        "        rerank_response = contextual_client.rerank.create(\n",
        "            query=query,\n",
        "            instruction=instruction,\n",
        "            documents=documents_to_rerank,\n",
        "            metadata=metadata_for_rerank,\n",
        "            model=\"ctxl-rerank-v2-instruct-multilingual\"\n",
        "        )\n",
        "\n",
        "        # Show top 3 results\n",
        "        console.print(\"Top 3 Results:\")\n",
        "        for i in range(min(3, len(rerank_response.results))):\n",
        "            result = rerank_response.results[i]\n",
        "            original_index = result.index\n",
        "            original_metadata = chroma_results['metadatas'][0][original_index]\n",
        "            console.print(f\"  {i+1}. {original_metadata['title']} (Score: {result.relevance_score:.3f})\")\n",
        "\n",
        "        console.print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Define different reranking strategies\n",
        "strategies = {\n",
        "    \"Recent Documents First\": \"Prioritize the most recent documents. Documents from 2025 should rank higher than older documents.\",\n",
        "    \"Internal Documents Priority\": \"Prioritize internal and confidential documents over public documents. Internal Use Only and Confidential documents should rank highest.\",\n",
        "    \"Department-Specific\": \"Prioritize documents from Sales and Engineering departments. Customer Success and Marketing documents should rank lower.\",\n",
        "    \"Source Authority\": \"Prioritize documents from NVIDIA Enterprise Sales Portal and Executive Team. External sources like TechAnalytics should rank lower.\"\n",
        "}\n",
        "\n",
        "# Compare strategies for the same query\n",
        "query = \"What is the current status and pricing for RTX 5090 enterprise GPUs?\"\n",
        "\n",
        "console = Console()\n",
        "console.print(Panel(\"ğŸ”„ COMPARING RERANKING STRATEGIES\", style=\"bold magenta\"))\n",
        "console.print(f\"Query: {query}\\n\")\n",
        "\n",
        "compare_reranking_strategies(query, strategies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6bHcq25dMaS"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates the powerful combination of Chroma and Contextual AI's instruction-following reranker for enhanced RAG pipelines.\n",
        "\n",
        "### What We Demonstrated:\n",
        "\n",
        "1. **Basic Chroma Retrieval**: Standard vector similarity search\n",
        "2. **Contextual AI Reranking**: Instruction-following reranking with custom business logic\n",
        "3. **Complete RAG Pipeline**: Chroma â†’ Reranking â†’ LLM Generation\n",
        "4. **Advanced Reranking Strategies**: Multiple instruction-based ranking approaches\n",
        "\n",
        "### Key Benefits of Contextual AI Reranker:\n",
        "\n",
        "- **Instruction-Following**: Handle complex business logic through natural language instructions\n",
        "- **BEIR Benchmark Leading**: State-of-the-art accuracy on industry benchmarks\n",
        "- **Multi-lingual Support**: Handle documents in multiple languages\n",
        "- **Metadata-Aware**: Leverage document metadata for intelligent ranking\n",
        "- **Conflict Resolution**: Handle conflicting information in retrieval results\n",
        "\n",
        "### Chroma Integration Advantages:\n",
        "\n",
        "- **Seamless Integration**: Easy to add reranking to existing Chroma workflows\n",
        "- **Metadata Preservation**: Maintain document metadata through the reranking process\n",
        "- **Flexible Retrieval**: Retrieve more documents than needed for optimal reranking\n",
        "- **Production Ready**: Scalable solution for enterprise applications\n",
        "\n",
        "### Use Cases Demonstrated:\n",
        "\n",
        "1. **Enterprise Document Search**: Prioritize internal documents over external sources\n",
        "2. **Technical Documentation**: Focus on engineering specifications over marketing materials\n",
        "3. **Temporal Relevance**: Weight recent documents higher than older ones\n",
        "4. **Authority-Based Ranking**: Prioritize authoritative sources and departments\n",
        "\n",
        "### Next Steps for Enhancement:\n",
        "\n",
        "- **Hybrid Search**: Combine keyword and semantic search with reranking\n",
        "- **Custom Instructions**: Develop domain-specific reranking instructions\n",
        "- **Performance Optimization**: Batch processing for large document collections\n",
        "- **Evaluation Metrics**: Measure reranking effectiveness with custom metrics\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to get started?** This notebook provides a complete, production-ready example of integrating Contextual AI's instruction-following reranker with Chroma for sophisticated RAG applications. The combination enables intelligent document ranking that goes beyond simple similarity to understand business context and requirements.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}